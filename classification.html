<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Classification models</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/Favicon-1.png" rel="icon">
  <link href="assets/img/Favicon-1.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <!-- Creating a python code section-->
  <link rel="stylesheet" href="assets/css/prism.css">
  <script src="assets/js/prism.js"></script>

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- To set the icon, visit https://fontawesome.com/account-->
  <script src="https://kit.fontawesome.com/5d25c1efd3.js" crossorigin="anonymous"></script>
  <!-- end of icon-->

  <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


  <!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/myphoto.jpeg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Arun</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/arunp77/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://github.com/arunp77" class="github"><i class="bx bxl-github"></i></a>
          <a href="https://twitter.com/arunp77_" class="twitter"><i class="bx bxl-twitter"></i></a>
          <a href="https://www.instagram.com/arunp77/" class="instagram"><i class="bx bxl-instagram"></i></a>
          <a href="https://arunp77.medium.com/" class="medium"><i class="bx bxl-medium"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
          <li><a href="index.html#skills-and-tools" class="nav-link scrollto"><i class="bx bx-wrench"></i> <span>Skills and Tools</span></a></li>
          <li><a href="index.html#services" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Services</span></a></li>
          <li><a href="index.html#professionalcourses" class="nav-link scrollto"><i class="bx bx-book-alt"></i> <span>Professional Certification</span></a></li>
          <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-news"></i> <span>Publications</span></a></li>
          <li><a href="index.html#extra-curricular" class="nav-link scrollto"><i class="bx bx-rocket"></i> <span>Extra-Curricular Activities</span></a></li>
          <li><a href="index.html#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

<main id="main">

        <!-- ======= Breadcrumbs ======= -->
        <section id="breadcrumbs" class="breadcrumbs">
          <div class="container">
    
            <div class="d-flex justify-content-between align-items-center">
              <h2></h2>
              <ol>
                <li><a href="portfolio-details-1.html" class="clickable-box">Content section</a></li>
                <li><a href="index.html#portfolio" class="clickable-box">Portfolio section</a></li>
              </ol>
            </div>
    
          </div>
        </section><!-- End Breadcrumbs -->

    <!------  right dropdown menue ------->
    <div class="right-side-list">
      
      <div class="dropdown">
          <button class="dropbtn"><strong>Shortcuts:</strong></button>
          <div class="dropdown-content">
              <ul>
                  <li><a href="cloud-compute.html"><i class="fas fa-cloud"></i> Cloud</a></li>
                  <li><a href="AWS-GCP.html"><i class="fas fa-cloud"></i> AWS-GCP</a></li>
                  <li><a href="amazon-s3.html"><i class="fas fa-cloud"></i> AWS S3</a></li>
                  <li><a href="ec2-confi.html"><i class="fas fa-server"></i> EC2</a></li>
                  <li><a href="Docker-Container.html"><i class="fab fa-docker" style="color: rgb(29, 27, 27);"></i> Docker</a></li>
                  <li><a href="Jupyter-nifi.html"><i class="fab fa-python" style="color: rgb(34, 32, 32);"></i> Jupyter-nifi</a></li>
                  <li><a href="snowflake-task-stream.html"><i class="fas fa-snowflake"></i> Snowflake</a></li>
                  <li><a href="data-model.html"><i class="fas fa-database"></i> Data modeling</a></li>
                  <li><a href="sql-basics.html"><i class="fas fa-table"></i> QL</a></li>
                  <li><a href="sql-basic-details.html"><i class="fas fa-database"></i> SQL</a></li>
                  <li><a href="Bigquerry-sql.html"><i class="fas fa-database"></i> Bigquerry</a></li>
                  <li><a href="scd.html"><i class="fas fa-archive"></i> SCD</a></li>
                  <li><a href="sql-project.html"><i class="fas fa-database"></i> SQL project</a></li>
                    <!-- Add more subsections as needed -->
                </ul>
          </div>
        </div>
    </div>

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">
        <div class="row gy-4">
          <h1>Classification in Machine Learning: An Introduction</h1>
          <div class="col-lg-8">
            <div class="portfolio-details-slider swiper">
              <div class="swiper-wrapper align-items-center">
                <div class="swiper-slide">
                    <figure>
                      <img src="assets/img/data-engineering/classification.png" alt="" style="max-width: 50%; max-height: 50%;">
                      <figcaption></figcaption>
                    </figure>
                </div>
              </div>
          </div>
        </div>

        <div class="col-lg-4 grey-box">
          
          <div class="section-title">
            <h3>Content</h3>
            <ol>
              <li><a href="#introduction">Introduction</a></li>
              <li><a href="#Relationship-of-regression-lines">Relationship of regression lines</a></li>
              <li><a href="#Types-of-Linear-Regression">Types of Linear Regression</a></li>
              <li><a href="#Mathematical-1">Mathematical Explanation</a></li>
              <li><a href="#Assumption-of-LR">Assumptions of Linear Regression</a></li>
              <li><a href="#evaluation-metrics-for-LR">Evaluation Metrics for Linear Regression</a></li>
              <li><a href="#overfit-goodfit-underfit">Overfitting, Good Fit, and Underfitting in Machine Learning</a></li>
              <li><a href="#reference">Reference</a></li>
          </ol>
          </div>
        </div>
      </div>

      <section id="introdction">
        <h2>Introduction</h2>
        Classification is a supervised machine learning task. Classification problems are an important category of problems 
        in analytics in which the outcome variable or response variable ('\(y\)') takes discrete values. Primary objective of a classification model is to predict 
        the probability of an observation belonging to a class, known as <strong>class probability</strong>.
        
        <p><strong>Example: </strong>For example, a spam filter can be used to classify emails as spam or not spam. A credit card fraud detection system can be used to classify transactions as legitimate or fraudulent.</p>
        
        <!----------------->
        <h3 id="Common-algorithms">Common classification algorithms</h3>
        Classification problems may have binary or multiple outcomes or classes. Binary outcomes are called 
        binary classification and multiple outcomes are called multinomial classification.
        There are several techniques used for solving classification problems such as: logistic regression classification trees i.e. decision tree learning discriminant analysis neural networks support vector machines.
        <ol>
          <li><strong>Logistic regression: </strong>Logistic regression is a statistical model that is used to predict the probability of a binary outcome (e.g., spam vs. not spam). It is a linear model, meaning that it assumes that 
            there is a linear relationship between the features of the data and the probability of the outcome.</li>
          <li><strong>Decision trees: </strong>Decision trees are a tree-like structure that represents a set of rules for making decisions. They are often used for classification tasks because they are easy to interpret and can 
            handle both numerical and categorical data.</li>
          <li><strong>K-nearest neighbors (KNN): </strong>KNN is a simple but effective classification algorithm that classifies new data points based on the majority class of their k nearest neighbors in the training data.</li>
          <li><strong>Support vector machines (SVMs): </strong>SVMs are a powerful classification algorithm that can handle both linear and nonlinear relationships between the features of the data and the outcome. They are 
            particularly useful for complex classification problems.</li>
          <li><strong>Naive Bayes: </strong>Naive Bayes is a probabilistic classifier that is based on Bayes' theorem. It is a simple and efficient algorithm that is often used for text classification tasks.</li>
        </ol>

        <!----------------------->
        <h3 id="Binary">Binary Logistic Regression</h3>
        Logistic regression is a statistical model in which the response variable takes a discrete value and the 
        explanatory variables can either be continuous or discrete. If the outcome variable takes only two values, 
        then the model is called binary logistic regression model. 

        <p>Logistic regression is statistical method used to model the probability of a outcome (i.e., outcome that can take on one of two values, such as 0 or 1, yes or no, etc.) based on one or more predictor variables. Mathematically, 
          logistic regression uses the logistic function, also known as the sigmoid function, to model the probability of the outcome.</p>

        <p>The logistic function is defined as:</p>

        $$P(Y=1 | X) = \frac{1}{1+e^{-z}}$$

        Here \(z\) is defined as:

        $$z = \theta_0 + \theta_1 x_1 + \theta_2 x_2+ ... \theta_n x_n = \theta^T x$$

        and
        <ul>
          <li>\(P(Y=1 | X)\) is the probability of the outcome,</li>
          <li>\(X = (x_1, x_2, ..., x_n)\) represents the input features variables.</li>
          <li>\(\theta_0\) is the intercept, \(\theta_1, \theta_2, ..., \theta_n\) are the coefficients for the  input features variables.</li>
          <li>\(z\) is the linear combination of the input features.</li>
          <li>\(\theta^T\) represents the transpose of the parameter vector.</li>
          <li>'\(e\)' is the base of the natural logarithm (approximately equal to 2.71828).</li>
        </ul>
        
        <figure>
          <img src="assets/img/machine-ln/logistic-fun.png" alt="" style="max-width: 70%; max-height: auto;">
          <figcaption></figcaption>
        </figure>
        
         

        <div class="box">
          Sometimes the logistic function is also represemnted in more compact form as:
          $$h_\theta(x) = \frac{1}{1+e^{-\theta^T x}}$$
          where:
          <ul>
            <li>\(h_\theta(x)\) is the predicted probability that \(y = 1\).</li>
            <li>\(\theta\) is the parameter vector</li>
            <li>\(x\) is the input feature vector</li>
          </ul>
        </div>

        The logistic function has an S-shaped curve (thus also known as Sigmoid function).
        The logistic function maps any real-valued number to a value between 0 and 1, which can be interpreted as a probability. The goal of logistic regression is to find the values of the coefficients that maximize the likelihood of 
        observing the data, given the model. This is typically done using maximum likelihood estimation. Once the coefficients have been estimated, the logistic regression model can be used to predict the probability of the outcome 
        for new observations. For example, if we have a new observation with predictor variables \(x_1=1, x_2=3\) and \(x_3=4\), and the estimated coefficients are \(\theta_0 = -1, \theta_1 =0.5, \theta_2 = 1\) and \(\theta_3 = 0.2\), 
        we can calculate the probability of the outcome as follows:
        
        $$z = -1 +0.52 +13 +0.2 \times 4 = 3.3$$

        and hence,

        $$P(Y = 1 | X) = \frac{1}{1+e^{-3.3}} = 0.96$$

        Therefore, the probability of the outcome for this new observation is 0.96. It's important to note that logistic regression assumes a linear relationship between the predictor variables and the log odds of the outcome. This means that the logistic 
        regression model assumes that the relationship between the predictor variables and the probability of the outcome can be modeled using a linear equation.
        
        <p>From above equation, we can re write following equations:</p>
        $$\text{ln}\left(\frac{P(Y=1 | X)}{1- P(Y=1 | X)}\right) = z = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n . $$
 
        The right hand side of the equation is a linear function. Such models are called <strong>generalized linear models (GLM)</strong>. In GLM, the errors may not follow normal distribution and there exists a transformation function of the outcome variable that takes a linear 
        functional form.

        <!----------------->
        <h3>Cost function for Logistic Regression</h3>
        The cost function for the logistic regression is used to quantify the error between preducted and actua; values.
        The objective is to minimize this cost. The cost function is defined as:
        $$J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \right] $$
        Here,
        <ul>
          <li>\(m\) is the number of training examples.</li>
          <li>\(y^{(i)}\) is the actual output for the i-th training example.</li>
          <li>\(h_\theta (x^{(i)})\) is the predicted output for the i-th training example using the logisict function.</li>
        </ul>
        The cost function penalizes large errors, and the logarithmic terms ensure that the cost is higher when the prediction is far from the actual value.

        In training, the goal is to find the parameter vector \(\theta\) that minimizes the cost function. This is often done using optimization algorithms like gradient descent.

        <!----------------->
        <h4>Gradient Descent Rule:</h4> 
        The gradient descent algorithm for the logistic regression aims to find the optimal parameters \(\theta\)
        that minimize the cost function. The update rule is derived from the partial derivatives of the cost function with respect to each parameter. 

        <p>The update rule for the gradient descent algorithm is as follows:</p>
        $$\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}$$

        where:
        <ul>
          <li>\(\theta_j\) is the j-th parameter (weight or coefficient).</li>
          <li>\(\alpha\) is the learning rate, a positive scalar determining the size of each step in the parameter  space.</li>
          <li>\(\frac{\partial J(\theta)}{\partial \theta_j}\) is the partial derivative of the cost function \(J(\theta)\) with respect to \(\theta_j\).</li>
        </ul>

        <h5>Algorith steps:</h5>
        <ol>
          <li>Initialize parameters: \(\theta_0, \theta_1, ..., \theta_n\).</li>
          <li>Repeat until convergence:
            <ul>
              <li>Update each parameter simultaneously using the update rule.</li>
              <li>Simultaneous update means calculating the new values of all parameters before applying them to the model.</li>
              <li>Repeat the update until the change in the cost function becomes small or a fixed number of iterations are reached.</li>
            </ul>
          </li>
        </ol>

        <!----------------->
        <h4>Model Interpretation</h4>
        <ul>
          <li>The logistic function outputs values between 0 and 1, representing probabilities.</li>
          <li>The decision boundary is where \(P(Y=1 | X) =0.5\). If \(P(Y=1 | X) > 0.5\), the instance is predicted to belong to class 1; otherwise, it belongs to class 0.</li>
        </ul>


        <!----------------->
        <div class="box">
          <h5><strong><a href="https://arunp77.github.io/Arun-Kumar-Pandey/Linear-reg.html#Maximum-likelihood-estimation" target="_blank">Maximum Likelihood Estimation (MLE)</a></strong></h5>
          Maximum Likelihood Estimation (MLE) is a statistical method used in the context of logistic regression (and more broadly in statistical modeling) to estimate the parameters of a model. In the case of logistic regression, MLE aims to find the set of parameters that maximizes the likelihood function, which measures how well the model explains the observed data.
          <p><strong>Mathematical Description:</strong>
          For logistic regression, let's denote the likelihood function as \(L(\theta)\), where \(\theta\) represents the parameters of the logistic regression model. The likelihood function is given by the product of the 
          probabilities of the observed outcomes under the current parameter values.</p>

          <p>For a binary classification problem (0 or 1), the likelihood function is often expressed as:</p>

          $$L(\theta) = \Pi_{i=1}^m P(y^{(i)}|x^{(i)}; \theta)^{y^{(i)}}\cdot \left(1-P(y^{(i)}|x^{(i)}; \theta)\right)^{1-y^{(i)}}.$$

          Here:

          <ul>
            <li>\(m\) is the number of training examples.</li>
            <li>\(y^{(i)}\) is the actual output for the i-th training example (0 or 1).</li>
            <li>\(x^{(i)}\) is the input feature vector for the i-th training example.</li>
            <li>\(P(y^{(i)|x^{(i); \theta}})\) is the predicted probabolity if the i-th example belonging to class 1.</li>
          </ul>

          In logistic regression, the predicted probability is given by the logistic function:

          $$P(y^{(i)} =1| x^{(i)}; \theta) = h_\theta(x^{(i)})$$

          $$P(y^{(i)} =0| x^{(i)}; \theta) = 1- h_\theta(x^{(i)})$$
          
          The goal of MLE is to find the values of \(\theta\) that maximize the likelihood function \(L(\theta)\). In practice, it 
          is often more convenient to maximize the log-likelihood function (logarithm of the likelihood function), denoted as \(l(\theta)\):

          $$l(\theta) = \sum_{i=1}^m \left[y^{(i)} \text{log}(h_\theta(x^{(i)}))- (1-y^{(i)})\text{log}(1-h_\theta(x^{(i)}))\right].$$

          Maximizing \(l(\theta)\) is equivalent to maximizing \(L(\theta)\), as the logrithm is a monotonically increasing function.

          <p>The logistic regression cost function \(J(\theta)\) that we discussed earlier is essentially the negative log-likelihood, with some scaling for convenience in optimization:</p>

          $$J(\theta) = -\frac{1}{m} l(\theta).$$

          So, in logistic regression, the optimization process, whether using gradient descent or another optimization algorithm, is essentially performing Maximum Likelihood Estimation to find the parameters that maximize the likelihood of observing the given set of training examples.


        </div>





        <!----------------->
        <h4>Training Objective</h4>
        The model is trained by finding the optimal values for \(\theta\) that minimize the prediction error. This is typically done using techniques like Maximum Likelihood Estimation (MLE).







      </section>

  
      <section id="Example">
        <ul>
            <li>You can go to <a href="https://github.com/arunp77/Machine-Learning/tree/main/Projects-ML" target="_blank">following project</a> for a reference for linear regression analysis. </li>
        </ul>
      </section>
     


      <!-------Reference ------->
      <section id="reference">
        <h2>References</h2>
        <ul>
          <li>My github Repositories on Remote sensing <a href="https://github.com/arunp77/Machine-Learning/" target="_blank">Machine learning</a></li>
          <li><a href="https://mlu-explain.github.io/linear-regression/" target="_blank">A Visual Introduction To Linear regression</a> (Best reference for theory and visualization).</li>
          <li>Book on Regression model: <a href="https://avehtari.github.io/ROS-Examples/" target="_blank">Regression and Other Stories</a></li>
          <li>Book on Statistics: <a href="https://hastie.su.domains/Papers/ESLII.pdf" target="_blank">The Elements of Statistical Learning</a></li>
          <li><a href="https://www.colorado.edu/amath/sites/default/files/attached-files/ch12_0.pdf">https://www.colorado.edu/amath/sites/default/files/attached-files/ch12_0.pdf</a></li>
        </ul>
      </section>

      <hr>
      
      <div style="background-color: #f0f0f0; padding: 15px; border-radius: 5px;">

        <h3>Some other interesting things to know:</h3>
        <ul style="list-style-type: disc; margin-left: 30px;">
            <li>Visit my website on <a href="sql-project.html">For Data, Big Data, Data-modeling, Datawarehouse, SQL, cloud-compute.</a></li>
            <li>Visit my website on <a href="Data-engineering.html">Data engineering</a></li>
        </ul>
      </div>
      <p></p>

      <div class="navigation">
          <a href="index.html#portfolio" class="clickable-box">
              <span class="arrow-left">Portfolio section</span>
          </a>
          
          <a href="portfolio-details-1.html" class="clickable-box">
              <span class="arrow-right">Content</span>
          </a>
      </div>
  </div>
</div>
</section><!-- End Portfolio Details Section -->
</main><!-- End #main --

<!-- ======= Footer ======= -->
<footer id="footer">
  <div class="container">
    <div class="copyright">
      &copy; Copyright <strong><span>Arun</span></strong>
    </div>
  </div>
</footer><!-- End  Footer -->

<a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

<!-- Vendor JS Files -->
<script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
<script src="assets/vendor/typed.js/typed.umd.js"></script>
<script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    hljs.initHighlightingOnLoad();
  });
</script>

</body>

</html>