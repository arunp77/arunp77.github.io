<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <title>Scala Spark</title>
    <meta content="" name="description">
    <meta content="" name="keywords">
    <!-- Favicons -->
    <link href="assets/img/Favicon-1.png" rel="icon">
    <link href="assets/img/Favicon-1.png" rel="apple-touch-icon">

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

    <!-- Vendor CSS Files -->
    <link href="assets/vendor/aos/aos.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
    <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
    <!-- Creating a python code section-->
    <link rel="stylesheet" href="assets/css/prism.css">
    <script src="assets/js/prism.js"></script>

    <!-- Template Main CSS File -->
    <link href="assets/css/style.css" rel="stylesheet">

    <!-- To set the icon, visit https://fontawesome.com/account-->
    <script src="https://kit.fontawesome.com/5d25c1efd3.js" crossorigin="anonymous"></script>
    <!-- end of icon-->

    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <!-- =======================================================
    * Template Name: iPortfolio
    * Updated: Sep 18 2023 with Bootstrap v5.3.2
    * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
    * Author: BootstrapMade.com
    * License: https://bootstrapmade.com/license/
    ======================================================== -->
</head>

<body>

    <!-- ======= Mobile nav toggle button ======= -->
    <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

    <!-- ======= Header ======= -->
    <header id="header">
    <div class="d-flex flex-column">
        <div class="profile">
            <img src="assets/img/myphoto.jpeg" alt="" class="img-fluid rounded-circle">
            <h1 class="text-light"><a href="index.html">Arun</a></h1>
            <div class="social-links mt-3 text-center">
                <a href="https://www.linkedin.com/in/arunp77/" target="_blank" class="linkedin"><i class="bx bxl-linkedin"></i></a>
                <a href="https://github.com/arunp77" target="_blank" class="github"><i class="bx bxl-github"></i></a>
                <a href="https://twitter.com/arunp77_" target="_blank" class="twitter"><i class="bx bxl-twitter"></i></a>
                <a href="https://www.instagram.com/arunp77/" target="_blank" class="instagram"><i class="bx bxl-instagram"></i></a>
                <a href="https://arunp77.medium.com/" target="_blank" class="medium"><i class="bx bxl-medium"></i></a>
            </div>
        </div>

        <nav id="navbar" class="nav-menu navbar">
            <ul>
                <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
                <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
                <li><a href="index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
                <li><a href="index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
                <li><a href="index.html#skills-and-tools" class="nav-link scrollto"><i class="bx bx-wrench"></i> <span>Skills and Tools</span></a></li>
                <li><a href="index.html#services" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Services</span></a></li>
                <li><a href="index.html#professionalcourses" class="nav-link scrollto"><i class="bx bx-book-alt"></i> <span>Professional Certification</span></a></li>
                <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-news"></i> <span>Publications</span></a></li>
                <li><a href="index.html#extra-curricular" class="nav-link scrollto"><i class="bx bx-rocket"></i> <span>Extra-Curricular Activities</span></a></li>
                <li><a href="index.html#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
            </ul>
        </nav><!-- .nav-menu -->
    </div>
    </header><!-- End Header -->

    <main id="main">
        <!-- ======= Breadcrumbs ======= -->
        <section id="breadcrumbs" class="breadcrumbs"> 
        <div class="container">
    
            <div class="d-flex justify-content-between align-items-center">
            <h2>Data Engineering</h2>
            <ol>
                <li><a href="Data-engineering.html" class="clickable-box">Content section</a></li>
                <li><a href="index.html#portfolio" class="clickable-box">Portfolio section</a></li>
            </ol>
            </div>
    
        </div>
        </section><!-- End Breadcrumbs -->

        <!------  right dropdown menue ------->
        <div class="right-side-list">
            <div class="dropdown">
                <button class="dropbtn"><strong>Shortcuts:</strong></button>
                <div class="dropdown-content">
                    <ul>
                        <li><a href="cloud-compute.html"><i class="fas fa-cloud"></i> Cloud</a></li>
                        <li><a href="AWS-GCP.html"><i class="fas fa-cloud"></i> AWS-GCP</a></li>
                        <li><a href="amazon-s3.html"><i class="fas fa-cloud"></i> AWS S3</a></li>
                        <li><a href="ec2-confi.html"><i class="fas fa-server"></i> EC2</a></li>
                        <li><a href="Docker-Container.html"><i class="fab fa-docker" style="color: rgb(29, 27, 27);"></i> Docker</a></li>
                        <li><a href="Jupyter-nifi.html"><i class="fab fa-python" style="color: rgb(34, 32, 32);"></i> Jupyter-nifi</a></li>
                        <li><a href="snowflake-task-stream.html"><i class="fas fa-snowflake"></i> Snowflake</a></li>
                        <li><a href="data-model.html"><i class="fas fa-database"></i> Data modeling</a></li>
                        <li><a href="sql-basics.html"><i class="fas fa-table"></i> QL</a></li>
                        <li><a href="sql-basic-details.html"><i class="fas fa-database"></i> SQL</a></li>
                        <li><a href="Bigquerry-sql.html"><i class="fas fa-database"></i> Bigquery</a></li>
                        <li><a href="scd.html"><i class="fas fa-archive"></i> SCD</a></li>
                        <li><a href="sql-project.html"><i class="fas fa-database"></i> SQL project</a></li>
                            <!-- Add more subsections as needed -->
                    </ul>
                </div>
            </div>
        </div>

        <!-- ======= Portfolio Details Section ======= -->
        <section id="portfolio-details" class="portfolio-details">
            <div class="container">
                <div class="row gy-4">
                    <h1>Scala Spark</h1>
                    <div class="col-lg-8">
                        <div class="portfolio-details-slider swiper">
                            <div class="swiper-wrapper align-items-center"> 
                                <figure>
                                    <img src="assets/img/data-engineering/Kafka-wall.png" alt="" style="max-width: 90%; max-height: auto;">
                                    <figcaption></figcaption>
                                </figure>
                            </div>
                            <div class="swiper-pagination"></div>
                        </div>
                    </div>

                    <div class="col-lg-4 grey-box">
                        <div class="section-title">
                            <h3>Table of Contents</h3>
                            <ol>
                                <li><a href="#introduction">Introduction</a></li>
                                <li><a href="#objective">Objective</a></li>
                                <ul>
                                    <li><a href="#buildsparksession">Building the SparkSession and loading the datasets</a></li>
                                    <li><a href="#select-categorical">Selecting the Categorical variables</a></li>
                                    <li><a href="#pipelines">Pipelines</a></li>
                                    <li><a href="#svmlib">Formatting the database in svmlib format</a></li>
                                    <li><a href="#application">Application of a Spark ML classifier</a></li>
                                    <li><a href="#model">Model prediction</a></li>
                                    <li><a href="#model-evaluate">Model evaluation</a></li>
                                </ul>
                                <li><a href="#reference">Reference</a></li>
                            </ol>
                        </div>
                    </div>
                </div>

                <section>
                    <h3 id="introduction">Introduction to Kafka</h3>
                    <p><a href="https://kafka.apache.org/quickstart" target="_blank">Apache Kafka</a> is an open-source distributed event streaming platform initially developed by LinkedIn in 2011 and later open-sourced as an Apache Software Foundation project. It is designed to handle real-time data feeds, allowing for the building of robust and scalable streaming data pipelines. Kafka is widely used in various industries for applications such as real-time analytics, log aggregation, monitoring, and messaging.</p>
                    <p> In Kafka, data communication revolves around the concepts of producers, topics, and consumers, which closely align with the pub/sub paradigm.</p>
                    <figure>
                        <img src="assets/img/data-engineering/kadka-producer-consumer.png" alt="" style="max-width: 50%; max-height: auto;">
                        <figcaption style="text-align: center;"><strong>&#169; Image credit:</strong> <a href="index.html">Arun Kumar Pandey</a></figcaption>
                    </figure>
                    <ul>
                        <li><strong>Producers</strong> act as data publishers, generating records and sending them to Kafka topics. These records can represent any type of data, such as log events, sensor readings, or user interactions. Producers are responsible for specifying the topic to which each record should be published.</li>
                        <li><strong>Topics</strong> serve as logical channels or categories to which records are published. Each topic represents a stream of related data, organized based on a common theme or subject. Topics can have one or more partitions to enable parallel processing and scalability.</li>
                        <li><strong>Consumers</strong> subscribe to topics of interest and consume messages from them. They read records from the partitions of the subscribed topics and process them according to their application logic. Multiple consumers can subscribe to the same topic, forming consumer groups for parallel processing and load balancing.</li>
                    </ul>
                    <p>In the pub/sub model, a producer produces or push a message to the broker, and broker will store the messages. Consumer will then consume the message from the broker. </p>

                    <br>

                    <p><strong>Example:</strong></p>
                    <figure>
                        <img src="assets/img/data-engineering/kafka-messaging.png" alt="" style="max-width: 90%; max-height: auto;">
                        <figcaption style="text-align: center;"><strong>&#169; Image credit:</strong> <a href="index.html">Arun Kumar Pandey</a></figcaption>
                    </figure>
                    <p>The diagram depicts a scenario where multiple services on the left side (Frontend, Hadoop, Database Slave, Chat Server) are communicating with various services on the right side (Database server, Security Systems, Real-time Monitoring, Other Services, Data Warehouse). Each service on the left side is connected to multiple services on the right side, indicating a complex network of communication channels.</p>
                    <p><strong>Major issues:</strong></p>
                    <ul>
                        <li><strong>Point-to-Point Communication: </strong> Without Kafka, each service on the left would directly communicate with multiple services on the right (int the first image). This results in a tightly coupled architecture where any change in one service may require changes in multiple other services, leading to complexity and maintenance challenges.</li>
                        <li><strong>Scalability: </strong>As the number of services increases (represented by 'n' services), the number of communication channels grows exponentially. Managing these point-to-point connections becomes increasingly difficult, leading to scalability issues.</li>
                        <li><strong>Fault Tolerance: </strong>Point-to-point communication lacks built-in fault tolerance mechanisms. If one service fails or becomes unavailable, it can disrupt the entire communication chain, leading to service outages and data loss.</li>
                        <li><strong>Data Loss and Inconsistency: </strong>In a direct communication setup, data loss or inconsistency may occur if a service fails to receive or process messages from another service. This can result in data discrepancies and integrity issues.</li>
                    </ul>
                    
                    <p><strong>Kafka Solution:</strong> Introducing Kafka as a middleware layer resolves these issues by decoupling communication between services and providing a distributed event streaming platform. The addition of Kafka as an intermediary between the left and right sides of the diagram brings several benefits:</p>
                    <ul>
                        <li><strong>Message Queuing:</strong> Kafka acts as a message queue, allowing services to publish messages (producing) to topics and consume messages (subscribing) from topics asynchronously. This decouples producers and consumers, enabling asynchronous and distributed communication.</li>
                        <li><strong>Scalability and Flexibility:</strong> Kafka's distributed architecture scales horizontally, allowing for the addition of new producers and consumers without impacting existing services. It provides flexibility in adding or removing services without disrupting the overall communication flow.</li>
                        <li><strong>Fault Tolerance and Durability:</strong> Kafka replicates data across multiple brokers, ensuring fault tolerance and data durability. If a broker or service fails, Kafka can continue to serve messages from replicated partitions, preventing data loss and maintaining system availability.</li>
                        <li><strong>Stream Processing:</strong>Kafka supports stream processing capabilities, enabling real-time data processing and analytics on streaming data. Services can consume and process data in real-time, leading to timely insights and actions</li>
                        <li><strong>Integration with Ecosystem:</strong>Kafka integrates seamlessly with various data processing frameworks and tools, such as Apache Spark, Apache Flink, and Apache Storm, enabling a rich ecosystem of data processing capabilities.</li>
                    </ul>
                    <p>By introducing Kafka as a central messaging backbone, the communication architecture becomes more resilient, scalable, and flexible. It addresses major issues such as point-to-point communication, scalability, fault tolerance, and data consistency, making the overall system more robust and reliable.</p>

                    <h4 id="components">Kafka components</h4>
                    <p>Apache Kafka comprises several key components that work together to provide a distributed event streaming platform. </p>
                    <ol>
                        <li><strong>Publishers (Producers):</strong> Producers are responsible for publishing records to Kafka topics. They generate records containing a key, a value, and an optional timestamp and send them to Kafka brokers. Producers can choose the partition to which a record should be sent or rely on Kafka's default partitioning mechanism.</li>
                        <li><strong>Consumer:</strong> Consumers subscribe to Kafka topics to consume records from them. They read records from partitions in a topic and process them according to their application logic. Consumers can be grouped into consumer groups for parallel processing and load balancing.</li>
                        <li><strong>Broker</strong> Kafka brokers are the fundamental building blocks of a Kafka cluster. They handle storage, replication, and serving of partitions of topics. Brokers receive messages from producers and deliver them to consumers. Kafka clusters typically consist of multiple brokers distributed across physical or virtual machines.</li>
                        <li><strong>Cluster:</strong> In Kafka, a cluster refers to a group of Kafka brokers working together to form a distributed messaging system. A Kafka cluster typically consists of multiple brokers, each running on separate physical or virtual machines. These brokers collaborate to store and serve data, handle client requests, and maintain cluster metadata. These are helpful when producer gernate a huge amount of data.</li>
                        <figure>
                            <img src="assets/img/data-engineering/kafka-cluster.png" alt="" style="max-width: 90%; max-height: auto;">
                            <figcaption style="text-align: center;"><strong>&#169; Image credit:</strong> <a href="index.html">Arun Kumar Pandey</a></figcaption>
                        </figure>
                        <li><strong>Topic:</strong> Topics represent streams of records, which are organized and categorized based on a common theme or subject. Producers publish records to topics, specifying the topic name to which the record should be sent. Consumers subscribe to topics to consume records from them.</li>
                        <li><strong>Partitions:</strong> Topics are divided into partitions, which are individual ordered sequences of records. Each partition can be hosted on multiple brokers for fault tolerance and scalability. Partitioning allows Kafka to parallelize data ingestion and consumption, enabling high throughput and efficient data processing.</li>
                        <figure>
                            <img src="assets/img/data-engineering/kafka-broker.png" alt="" style="max-width: 50%; max-height: auto;">
                            <figcaption style="text-align: center;">Since Kafka is a distributed system, in such a scenario we can break Kakfa topic into multiple parts and distribute those parts into different machines. This is known as partioning and each part is called as partition. So whenever, a producer send a message then it can go and sit into any of the partions. So as soon as a message arrives in partion, a number is assigned to them and they are known as offset numbers. These messages will be consumed by consumer. If we have single consumer then he/she can consume from each and every partions. On such kind of systems, if just one user is consuming the messages/events then it can perform upto it's capacity. So what we can do, we can create n-number consumer instances. In this case, we can group some users with a group name. For example in a payment systems, we can create a group with 'payment_consumer_group' and 'transaction_group' etc. So in the case of 'payment_consumer_group', we can devide the work load to each and every consumer to achive better output. <strong>&#169; Image credit:</strong> <a href="index.html">Arun Kumar Pandey</a></figcaption>
                        </figure>
                        <li><strong>Offset:</strong> In Kafka, an offset represents the position of a consumer within a partition of a topic. It is a numeric value that uniquely identifies a message within the partition. Each message in a partition is assigned a sequential offset, starting from 0 for the first message and increasing incrementally for subsequent messages. Offsets allow consumers to keep track of which messages they have already consumed within a partition. This enables consumers to resume reading from where they left off in case of failures or restarts. Consumers use offsets to determine the next message they need to read from a partition. By maintaining the offset of the last processed message, consumers can retrieve subsequent messages for processing. Consumers can commit their current offset to Kafka to indicate that they have successfully processed messages up to that point. This commit is typically done atomically along with processing logic to ensure exactly-once processing semantics.</li>
                        <li><strong>Consumer Group: </strong> A consumer group is a logical grouping of consumers that jointly consume and process records from one or more partitions of a topic. Each partition within a topic is consumed by exactly one consumer within a consumer group, enabling parallel processing and load distribution.</li>
                        <li><strong>Zookeper:</strong> ZooKeeper is used by Kafka for managing cluster metadata, leader election, and synchronization. It maintains information about brokers, topics, partitions, and consumer group membership. While ZooKeeper was a critical component in earlier versions of Kafka, newer versions are gradually moving towards removing this dependency.</li>
                        <figure>
                            <img src="assets/img/data-engineering/kafka-zookeeper.png" alt="" style="max-width: 70%; max-height: 50%;">
                            <figcaption style="text-align: center;"><strong>&#169; Image credit:</strong> <a href="index.html">Arun Kumar Pandey</a></figcaption>
                        </figure>
                    </ol>

                    <!------------------------>
                    <h3 id="instalation">Kafka installation: set in local machine</h3>
                    <p>Installing Apache Kafka involves several steps, including downloading the Kafka distribution, configuring the environment, starting the Kafka server, and verifying the installation. Below is a guide to help you with the installation process:</p>
                    <ol>
                        <li><strong>Prerequisites::</strong> Java: Kafka requires Java to be installed on your system. Make sure you have Java installed (To install go to linl and install <a href="https://www.java.com/en/download/help/download_options.html" target="_blank"> preferably Java 8 or later</a>)</li>
                        <li><strong>Download Kafka:</strong>
                            <ul>
                                <li>Visit the Apache Kafka website (https://kafka.apache.org/downloads) and download the latest stable version of Kafka.</li>
                                <li>Choose the appropriate binary distribution based on your operating system (e.g., Kafka for Scala 2.13 if you're using Scala 2.13).</li>
                            </ul>
                            <p>Once the download is complete, extract the Kafka archive to a directory of your choice using a file extraction tool (e.g., tar for Linux/Mac or 7-Zip for Windows).</p>
                        </li>
                        <li><strong></strong></li>
                        <li><strong></strong></li>
                        <li><strong></strong></li>
                        <li><strong></strong></li>
                        <li><strong></strong></li>
                        <li><strong></strong></li>
                        <li><strong></strong></li>
                    </ol>

                    

















                </section>

                

                <!-------Reference ------->
                <section id="reference">
                    <h3>References</h3>
                    <ol>
                        <li><a href="https://spark.apache.org/documentation.html" target="_blank"> Official Documentation</a></li>
                        <li><a href="https://www.databricks.com/learn/training/login" target="_blank">Databricks Learning Academy</a></li>
                        <li><a href="https://sparkbyexamples.com/" target="_blank">Spark by Examples</a></li>
                        <li><a href="https://www.datacamp.com/tutorial/pyspark-tutorial-getting-started-with-pyspark" target="_blank">Datacamp tutorial</a>.</li>
                        <li>For databricks, you can look at tutorial videos on youtube at <a href="https://www.youtube.com/watch?v=ChISx0-cMpU" target="_blank">youtube video by Bryan Cafferky</a>, 
                            writer of the book "Master Azure Databricks". A great playlist for someone who just want to learn about the big data analytics at Databricks Azure cloud platform.</li>
                        <li>See the video for <a href="https://www.youtube.com/watch?v=_C8kWso4ne4" target="_blank">pyspark basics by Krish Naik</a>. Great video for starter.</li>
                        <li><a href="https://www.youtube.com/watch?v=QLGrLFOzMRw" target="_blank">Great youtube on Apache spark</a> one premise working.</li>
                    </ol> 
                </section>

                <hr>
            
                <div style="background-color: #f0f0f0; padding: 15px; border-radius: 5px;">

                    <h3>Some other interesting things to know:</h3>
                    <ul style="list-style-type: disc; margin-left: 30px;">
                        <li>Visit my website on <a href="sql-project.html">For Data, Big Data, Data-modeling, Datawarehouse, SQL, cloud-compute.</a></li>
                        <li>Visit my website on <a href="Data-engineering.html">Data engineering</a></li>
                    </ul>
                </div>
                <p></p>

                <div class="navigation">
                    
                    <a href="index.html#portfolio" class="clickable-box">
                        <span class="arrow-left">Portfolio section</span>
                    </a>
                    
                    <a href="Data-engineering.html" class="clickable-box">
                        <span class="arrow-right">Content</span>
                    </a>

                </div>
            </div>
        </section><!-- End Portfolio Details Section -->
    </main><!-- End #main --

    <!-- ======= Footer ======= -->
    <footer id="footer">
    <div class="container">
        <div class="copyright">
        &copy; Copyright <strong><span>Arun</span></strong>
        </div>
    </div>
    </footer><!-- End  Footer -->

    <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

    <!-- Vendor JS Files -->
    <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
    <script src="assets/vendor/aos/aos.js"></script>
    <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
    <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
    <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
    <script src="assets/vendor/typed.js/typed.umd.js"></script>
    <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
    <script src="assets/vendor/php-email-form/validate.js"></script>

    <!-- Template Main JS File -->
    <script src="assets/js/main.js"></script>

    <script>
    document.addEventListener("DOMContentLoaded", function () {
        hljs.initHighlightingOnLoad();
    });
    </script>

</body>

</html> 