<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Ridge-Lasso</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/Favicon-1.png" rel="icon">
  <link href="assets/img/Favicon-1.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <!-- Creating a python code section-->
  <link rel="stylesheet" href="assets/css/prism.css">
  <script src="assets/js/prism.js"></script>

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- To set the icon, visit https://fontawesome.com/account-->
  <script src="https://kit.fontawesome.com/5d25c1efd3.js" crossorigin="anonymous"></script>
  <!-- end of icon-->

  <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


  <!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/myphoto.jpeg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Arun</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/arunp77/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://github.com/arunp77" class="github"><i class="bx bxl-github"></i></a>
          <a href="https://twitter.com/arunp77_" class="twitter"><i class="bx bxl-twitter"></i></a>
          <a href="https://www.instagram.com/arunp77/" class="instagram"><i class="bx bxl-instagram"></i></a>
          <a href="https://medium.com/@arunp77" class="medium"><i class="bx bxl-medium"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
          <li><a href="index.html#skills-and-tools" class="nav-link scrollto"><i class="bx bx-wrench"></i> <span>Skills and Tools</span></a></li>
          <li><a href="index.html#services" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Services</span></a></li>
          <li><a href="index.html#professionalcourses" class="nav-link scrollto"><i class="bx bx-book-alt"></i> <span>Professional Certification</span></a></li>
          <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-news"></i> <span>Publications</span></a></li>
          <li><a href="index.html#extra-curricular" class="nav-link scrollto"><i class="bx bx-rocket"></i> <span>Extra-Curricular Activities</span></a></li>
          <li><a href="index.html#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

<main id="main">

        <!-- ======= Breadcrumbs ======= -->
        <section id="breadcrumbs" class="breadcrumbs"> 
          <div class="container">
    
            <div class="d-flex justify-content-between align-items-center">
              <h2>Machine learning</h2>
              <ol>
                <li><a href="portfolio-details-1.html" class="clickable-box">Content section</a></li>
                <li><a href="index.html#portfolio" class="clickable-box">Portfolio section</a></li>
              </ol>
            </div>
    
          </div>
        </section><!-- End Breadcrumbs -->

    <!------  right dropdown menue ------->
    <div class="right-side-list">
      <div class="dropdown">
          <button class="dropbtn"><strong>Shortcuts:</strong></button>
          <div class="dropdown-content">
              <ul>
                  <li><a href="cloud-compute.html"><i class="fas fa-cloud"></i> Cloud</a></li>
                  <li><a href="AWS-GCP.html"><i class="fas fa-cloud"></i> AWS-GCP</a></li>
                  <li><a href="amazon-s3.html"><i class="fas fa-cloud"></i> AWS S3</a></li>
                  <li><a href="ec2-confi.html"><i class="fas fa-server"></i> EC2</a></li>
                  <li><a href="Docker-Container.html"><i class="fab fa-docker" style="color: rgb(29, 27, 27);"></i> Docker</a></li>
                  <li><a href="Jupyter-nifi.html"><i class="fab fa-python" style="color: rgb(34, 32, 32);"></i> Jupyter-nifi</a></li>
                  <li><a href="snowflake-task-stream.html"><i class="fas fa-snowflake"></i> Snowflake</a></li>
                  <li><a href="data-model.html"><i class="fas fa-database"></i> Data modeling</a></li>
                  <li><a href="sql-basics.html"><i class="fas fa-table"></i> QL</a></li>
                  <li><a href="sql-basic-details.html"><i class="fas fa-database"></i> SQL</a></li>
                  <li><a href="Bigquerry-sql.html"><i class="fas fa-database"></i> Bigquerry</a></li>
                  <li><a href="scd.html"><i class="fas fa-archive"></i> SCD</a></li>
                  <li><a href="sql-project.html"><i class="fas fa-database"></i> SQL project</a></li>
                    <!-- Add more subsections as needed -->
                </ul>
          </div>
        </div>
    </div>

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">
        <div class="row gy-4">
          <h1>Ridge Lasso and Elasticnet Machine learning algorithms</h1>
          <div class="col-lg-8">
            <div class="portfolio-details-slider swiper">
              <div class="swiper-wrapper align-items-center"> 
                <figure>
                  <img src="assets/img/machine-ln/ridge-lasso.png" alt="" style="max-width: 60%; max-height: auto;">
                  <figcaption style="text-align: center;"></figcaption>
                </figure>
              </div>
            <div class="swiper-pagination"></div>
          </div>
        </div>

        <div class="col-lg-4 grey-box">
          
          <div class="section-title">
            <h3>Content</h3>
            <ol>
              <li><a href="#introduction">Introduction</a></li>
              <li><a href="#ridge">Ridge Regression</a></li>
              <li><a href="#lasso">Lasso Regression</a></li>
              <li><a href="#elasticnet">Elasticnet</a></li>
              <li><a href="Example">Example</a></li>
              <li><a href="#reference">Reference</a></li>
            </ol>
          </div>
        </div>
      </div>

      <section id="introduction">
        <h2>Introduction</h2>
        Ridge and Lasso regression are regularization techniques used in linear regression to prevent overfitting and improve the model's generalization performance. Both methods introduce a penalty term to the linear regression cost function.
        <!----------------------------->
        <h3 id="ridge">Ridge Regression (reduce overfitting)</h3>
        Ridge regression, also known as Tikhonov regularization or L2 regularization, adds the squared sum of the coefficients to the cost function. This regularization method is used to reduce overfitting.
         The regularization term is proportional to the square of the
        L2 norm of the coefficients:
        $$\text{Ridge Cost Function} = \frac{1}{2m}\sum_{i=1}^m\left(h_\beta(x^{(i)}) - y^{(i)}\right)^2 + \alpha \sum_{i=1}^n \beta_i^2$$
        where:
        <ul>
            <li>\(m\) is the number of training examples.</li>
            <li>\(h_\beta(x^{(i)})\) is the predicted value for the \(i-\)th example.</li>
            <li>\(y^{(i)}\) is the actual output for the \(i-\)th example.</li>
            <li>\(\beta_i\) is the coefficient associated with the \(i-\)th feature.</li>
        </ul>
        here <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>α</mi></math> is the regularization strength. Ridge regression tends to shrink the coefficients towards zero but does not lead to exact zero coefficients.
        The firat term in the above equation is nothing but 'Least Squares Cost Function' used in the gradient decent method. 
        <p><strong>Ridge optimization:</strong></p>
        The goal is to find the value of \(\beta\) that minmize the Ridge cost function. The optimization problem can be stated as:
        $$\underset{\beta}{min} \left(\frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)}) - y^{(i)}\right)^2 +\alpha \sum_{i=1}^n \beta_i^2\right)$$
        
        
        <figure>
            <img src="assets/img/machine-ln/lasso-jtheta.png" alt="" style="max-width: 60%; max-height: auto;">
            <figcaption style="text-align: center;">Ridge Cost function. Here \(\lambda =0\) correspond to the gradient dicent cost function. It is clear that, as \(\lambda\) increases, 
            global minima also decreases, but it will never reach 0.
        </figcaption>
          </figure>
          In simpler terms, without the last term in the Lasso cost function, the model might overfit the data by assigning too much importance to all features. However, with the addition of the last term, Lasso introduces a mechanism that can shrink some coefficients to exactly zero. This results in a more parsimonious model by effectively eliminating the influence of certain features.
          <p>Let's illustrate with an example:</p>
          <ul>
            <li>Suppose our linear regression model without Lasso regularization is:</li>
             $$h_\theta(x) = \theta_0 +\theta_1 x_1 +\theta_2 x_2+\theta_3 x_3 = 0.34+ 0.48 x_1 + 0.52 x_2 + 0.24 x_3$$
             <li>Now, when we apply Lasso regularization, it can reduce the coefficients, leading to a simpler model:</li>
             $$h_\theta(x) =  0.34+ 0.32 x_1 + 0.40 x_2 + 0.12 x_3$$
             <li>This means Lasso automatically diminishes the reliance on certain features, in this case, reducing the dependence on the last feature (\(x_3\)) which was already deemed insignificant. The regularization process aids in feature selection, promoting a more robust and interpretable model.</li>
          </ul>

        <p>In Scikit-learn, Ridge regression is implemented in the `<code>Ridge</code>` class.</p>


        <!----------------------------->
        <h3 id="lasso">Lasso Regression (feature selection)</h3>
        Lasso regression, or L1 regularization, adds the sum of the absolute values of the coefficients to the cost function. The regularization term is proportional to the L1 norm of the coefficients: 
        
        $$\text{Lasso Cost Function} = \frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)}) - y^{(i)}\right)^2+ \alpha \sum_{i=1}^n |\beta_i|.$$
        
        Similar to Ridge regression, <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>α</mi></math> is the regularization strength. 
        Lasso regression has the property of producing sparse models by setting some coefficients to exact zero. What it means is that the features that are not that important will automatically get deleted
        and features that are very very important will be considered.

        <h5>Lasso Optimization</h5>
        The goal is to find the value of \(\beta\) that minmize the Lasso cost function. The optimization problem can be stated as:
        $$\underset{\beta}{min} \left(\frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)}) - y^{(i)}\right)^2 +\alpha \sum_{i=1}^n |\beta_i|\right)$$
        
        <h5>Example:</h5>
        When you apply the Lasso method to the linear regression model:
        $$h_\theta(x) = \theta_0 +\theta_1 x_1 +\theta_2 x_2+\theta_3 x_3 = 0.34+ 0.48 x_1 + 0.52 x_2 + 0.24 x_3$$
        Lasso introduces a penalty term to the cost function that contains the absolute values of the coefficients \(\propto \alpha \sum_{i=1}^n |\beta_i|\), where
        \(\alpha\) is the regularization strength. When using Lasso, it tends to shrink the coefficients towards zero, and it may even set some coefficients exactly to zero. The process of setting Some
        coefficients to zero is what makes Lasso particulalry useful for feature selection.

        <p>In simpler terms, Lasso may lead to a model with fewer features by reducing the impact of less important features, possibly making the equation look like:</p>
        $$h_\theta(x)= 0.34+ 0.32 x_1 + 0.40 x_2 + 0.12 x_3$$
        Notice how some coefficients have been reduced, and it might indicate that the Lasso method has identified and downplayed less influential features, making the model more parsimonious and potentially improving its generalization to new data.

        <h5>Difference between the Ridge and Lasso</h5>
        <ul>
            <li><strong>Ridge:</strong> Ridge might shrink the coefficients, but it won't set them exactly to zero. It will encourage smaller values fo \(\theta_i\)</li>
            <li><strong>Lasso:</strong> Lasso might not only shrink the coefficients but could also set some of them exactly to zero. It tends to prefer sparsity in the model, making it useful for feature selection.</li>
        </ul>
        In summary, Ridge and Lasso provide different regularization techniques with Ridge being more continuous in its shrinking effect, while Lasso introduces a sparsity element by potentially eliminating some features entirely. The choice between them depends on the specific characteristics of your data and the desired properties of your model.

        <p>In Scikit-learn, Lasso regression is implemented in the '<code>Lasso</code>' class.</p>

        <p><strong>Usage in scikit-learn:</strong></p>
        <pre class="language-python"><code>
            from sklearn.linear_model import Ridge, Lasso
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import StandardScaler
            
            # Assuming X_train, X_test, y_train, y_test are defined
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Ridge Regression
            ridge_reg = Ridge(alpha=1.0)  # Adjust alpha as needed
            ridge_reg.fit(X_train_scaled, y_train)
            ridge_score = ridge_reg.score(X_test_scaled, y_test)
            
            # Lasso Regression
            lasso_reg = Lasso(alpha=1.0)  # Adjust alpha as needed
            lasso_reg.fit(X_train_scaled, y_train)
            lasso_score = lasso_reg.score(X_test_scaled, y_test)            
        </code></pre>

        <!----------------------------->
        <h3 id="elasticnet">Elastic Net</h3>
        Elastic Net is a regularization technique that combines both L1 (Lasso) and L2 (Ridge) regularization terms in the linear regression cost function. 
        It is particularly useful when dealing with datasets that have a large number of features, and some of these features are correlated. 
        The Elastic Net cost function is a combination of the L1 and L2 regularization terms:
        
        $$\text{Elastic Net Cost Function} = \frac{1}{2m}\sum_{i=1}^m\left(h_\beta(x^{(i)}) - y^{(i)}\right)^2 + \alpha \left(\rho \sum_{i=1}^n |\beta_i| +\frac{1-\rho}{2} \sum_{i=1}^n \beta_i^2 \right)$$

        where:
        <ul>
            <li>Least Squares Cost Function is the standard least squares cost function, which measures the difference between predicted and actual values.</li>
            <li><math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>α</mi></math> is the total regularization strength, controlling the overall amount of regularization applied.</li>
            <li><math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>ρ </mi></math> is the mixing parameter that determines the balance between the L1 and L2 regularization. It basically control the trade-off betwee the L1 and L2 regularization.
                When:
                <ul>
                    <li>\(\rho= 0 \Rightarrow\) Elastic Net is equivalent to Ridge (L2 regularization), </li>
                    <li>\(\rho= 1 \Rightarrow\) it is equivalent to Lasso (L1 regularization only). </li>
                </ul>
            </li>
        </ul>
        The terms \(\sum_{i=1}^n |\beta_i|\) and  \(\sum_{i=1}^n \beta_i^2\) represents the L1 and L2 regularization penalties applied to the coefficients \(\beta_i\) respectively. 
        The coefficients \(\beta_i\) are the parameters being optimized during the training process. 

        <p>In mathematical terms, if \(X\) is the feature matrix, \(\beta\) is the vector of coefficients, and \(y\) is the target variables, the Elastic Net cost function can be written as:</p>

        $$J(\beta) = \frac{1}{2m} \sum_{i=1}^m \left(y_i - X_i \beta\right)^2 +\alpha \left(\rho \sum_{i=1}^n |\beta_i| +\frac{1-\rho}{2}\sum_{i=1}^n \beta_i^2\right)$$

        where 
        <ul>
            <li>\(m\) = is the number of samples</li>
            <li>\(n\) is the number of features</li>
            <li>\(y_i\) is the target values</li>
            <li>\(X_i\) is the featur vectors </li>
        </ul>

        <h5>When to Use Elastic Net</h5>
        <ul>
            <li>Use Elastic Net when you suspect that there is multicollinearity among your features and you also want the benefit of feature selection.</li>
            <li>It is a more flexible regularization method as it allows you to tune the balance between L1 and L2 penalties.</li>
        </ul>

        In summary, Elastic Net provides a balanced regularization approach that incorporates the advantages of both Lasso and Ridge regression, offering flexibility in handling different types of datasets.




      </section>


         

      <!-------Reference ------->
      <section id="reference">
        <h2>References</h2>
        <ul>
          <li>My github Repositories on Remote sensing <a href="https://github.com/arunp77/Machine-Learning/" target="_blank">Machine learning</a></li>
          <li><a href="https://mlu-explain.github.io/linear-regression/" target="_blank">A Visual Introduction To Linear regression</a> (Best reference for theory and visualization).</li>
          <li>Book on Regression model: <a href="https://avehtari.github.io/ROS-Examples/" target="_blank">Regression and Other Stories</a></li>
          <li>Book on Statistics: <a href="https://hastie.su.domains/Papers/ESLII.pdf" target="_blank">The Elements of Statistical Learning</a></li>
          <li>A nice mathematical description is available at <a href="https://www.youtube.com/watch?v=lv5IEOItgWM&t=1278s&ab_channel=KrishNaik" target="_blank">youtube video</a>.</li>
          <li><a href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html" target="_blank"> Lasso model selection and cross validation</a></li>
        </ul>
      </section>

      <hr>
      
      <div style="background-color: #f0f0f0; padding: 15px; border-radius: 5px;">

        <h3>Some other interesting things to know:</h3>
        <ul style="list-style-type: disc; margin-left: 30px;">
            <li>Visit my website on <a href="sql-project.html">For Data, Big Data, Data-modeling, Datawarehouse, SQL, cloud-compute.</a></li>
            <li>Visit my website on <a href="Data-engineering.html">Data engineering</a></li>
        </ul>
      </div>
      <p></p>

      <div class="navigation">
          <a href="index.html#portfolio" class="clickable-box">
              <span class="arrow-left">Portfolio section</span>
          </a>
          
          <a href="portfolio-details-1.html" class="clickable-box">
              <span class="arrow-right">Content</span>
          </a>
      </div>
  </div>
</div>
</section><!-- End Portfolio Details Section -->
</main><!-- End #main --

<!-- ======= Footer ======= -->
<footer id="footer">
  <div class="container">
    <div class="copyright">
      &copy; Copyright <strong><span>Arun</span></strong>
    </div>
  </div>
</footer><!-- End  Footer -->

<a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

<!-- Vendor JS Files -->
<script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
<script src="assets/vendor/typed.js/typed.umd.js"></script>
<script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    hljs.initHighlightingOnLoad();
  });
</script>

</body>

</html>