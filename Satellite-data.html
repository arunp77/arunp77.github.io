<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Data processing</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/Favicon-1.png" rel="icon">
  <link href="assets/img/Favicon-1.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <!-- Creating a python code section-->
  <link rel="stylesheet" href="assets/css/prism.css">
  <script src="assets/js/prism.js"></script>


  <!-- To set the icon, visit https://fontawesome.com/account-->
  <script src="https://kit.fontawesome.com/5d25c1efd3.js" crossorigin="anonymous"></script>
  <!-- end of icon-->

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
  

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha384-oGqqFhf3ELCpQk69FVb6jGrwPOTR5SO5FeECBbCFgrFJzVpXJFLHc06dL/iPzCBJe" crossorigin="anonymous">

  <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/myphoto.jpeg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Arun</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/arunp77/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://github.com/arunp77" class="github"><i class="bx bxl-github"></i></a>
          <a href="https://twitter.com/arunp77_" class="twitter"><i class="bx bxl-twitter"></i></a>
          <a href="https://www.instagram.com/arunp77/" class="instagram"><i class="bx bxl-instagram"></i></a>
          <a href="https://arunp77.medium.com/" class="medium"><i class="bx bxl-medium"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
          <li><a href="index.html#skills-and-tools" class="nav-link scrollto"><i class="bx bx-wrench"></i> <span>Skills and Tools</span></a></li>
          <li><a href="index.html#services" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Services</span></a></li>
          <li><a href="index.html#professionalcourses" class="nav-link scrollto"><i class="bx bx-book-alt"></i> <span>Professional Certification</span></a></li>
          <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-news"></i> <span>Publications</span></a></li>
          <li><a href="index.html#extra-curricular" class="nav-link scrollto"><i class="bx bx-rocket"></i> <span>Extra-Curricular Activities</span></a></li>
          <li><a href="index.html#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

<main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section id="breadcrumbs" class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Data processing</h2>
          <ol>
            <li><a href="Remote-sensing-content.html" class="clickable-box"><i class="fas fa-arrow-left"></i> Remote sensing content </i></a></li>
            <li><a href="index.html#portfolio" class="clickable-box"> Go to portfolio <i class="fas fa-arrow-right"></i></a></li>
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->

    <!------  right dropdown menue ------->
    <div class="right-side-list">
        <div class="dropdown">
            <button class="dropbtn"><strong>Shortcuts:</strong></button>
            <div class="dropdown-content">
                <ul>
                    <li><a href="cloud-compute.html"><i class="fas fa-cloud"></i> Cloud</a></li>
                    <li><a href="AWS-GCP.html"><i class="fas fa-cloud"></i> AWS-GCP</a></li>
                    <li><a href="amazon-s3.html"><i class="fas fa-cloud"></i> AWS S3</a></li>
                    <li><a href="ec2-confi.html"><i class="fas fa-server"></i> EC2</a></li>
                    <li><a href="Docker-Container.html"><i class="fab fa-docker" style="color: rgb(19, 18, 18);"></i> Docker</a></li>
                    <li><a href="Jupyter-nifi.html"><i class="fab fa-python" style="color: rgb(17, 16, 16);"></i> Jupyter-nifi</a></li>
                    <li><a href="snowflake-task-stream.html"><i class="fas fa-snowflake"></i> Snowflake</a></li>
                    <li><a href="data-model.html"><i class="fas fa-database"></i> Data modeling</a></li>
                    <li><a href="sql-basics.html"><i class="fas fa-table"></i> QL</a></li>
                    <li><a href="sql-basic-details.html"><i class="fas fa-database"></i> SQL</a></li>
                    <li><a href="Bigquerry-sql.html"><i class="fas fa-database"></i> Bigquerry</a></li>
                    <li><a href="scd.html"><i class="fas fa-archive"></i> SCD</a></li>
                    <li><a href="sql-project.html"><i class="fas fa-database"></i> SQL project</a></li>
                      <!-- Add more subsections as needed -->
                  </ul>
            </div>
          </div>
      </div>


    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">
          <div class="row gy-4">
            <div style="background-color: rgb(115, 228, 243); color: rgb(29, 27, 27); padding: 10px;">
              <h1>Process levels</h1>
          </div>
          <div class="image">
            <figure style="text-align: center;">
                <img src="assets/img/remote-sensing/sentinal=EUMESAT.png" alt="" style="max-width: 80%; max-height: 80%;">
                <br><figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://www.eumetsat.int/" target="_blank"> EUMESAT</a></figcaption>
            </figure>            
          </div>

          <section id="section-1">
            <h2>Various aspects of Satellite data collection </h2>
            The process of remote sensing, from data collection to final image processing, involves several stages. Here's a detailed description of each stage:
            <figure style="text-align: center;">
              <img src="assets/img/remote-sensing/remote-dataprocessing.png" alt="" style="max-width: 70%; max-height: 70%;">
              <figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://www.dlr.de/eoc/en/PortalData/60/Resources/dokumente/2_dfd/Final_DFD_Statusreport_2013-2021.pdf" target="_blank"> EO Data Management Systems</a></figcaption>
            </figure>  
            <ol>
              <li><strong>Platform and Sensor Selection: </strong>First step is to choose appropriate satellite, aircraft, or unmanned aerial Vehicle (UAV)
              platform and hence the sensors onboard on the specific objectives of the remote sensing mission. These sensors then captures data in relevat 
              spectral bands for the desired applications (example optical, infrared, radar).</li>
              <li><strong>Mission Planning and Scheduling: </strong>Next step would be to choose the orbits to cover the target area after 
                considering the lighting conditions, weather and other mission constrains.</li>
              <li><strong>Data Acquisition: </strong>Then the sensors onboards acquire remote sensing data through capturning the electromagnetic radiation in various wavelengths. 
                When utilizing optical sensors, the collection of data is accomplished by depending on sunlight reflection and absorption. In contrast, with radar sensors, 
                the sensors emit microwave signals, and the captured data comes from the signals that are backscattered. </li>
              <li><strong>Telemetry and Data Transmission: </strong>In the next step, the acquired data is transmitted to ground stations using telemetry systems. 
                Telemetry data includes details such as the satellite's health, its orientation in space, power levels, and sensor status.</li>
              <li><strong> Data Preprocessing: </strong>In this step, various data corrections (radiometric and geometric distortions introduced during data acquisition) are done.
              Atmospheric correction are also done in this step. The normalization and standardization of pixel values are also done for consistency.</li>
              <li><strong>Image Registration:</strong>Next multiple images from different times or sensors are aligned to a common coordiante system. 
                Also geometric distortions are corrected to enable accurate comparison and analysis.</li>
              <li><strong>Image Enhancement: </strong>Image emhancement is done to improve the visual quality and highlight specific features using techniques like contrast adjustment
              and histogram equalization. If required, specific spectral bands are enhanced to emphaseze certain infromation.</li>
              <li><strong>Image Classification: </strong>Pixels or regions are assigned within the images to predefined classes or land cover types. These are done by using classification 
              algorithms based on spectral, textural and contextual features. </li>
              <li><strong>Feature Extraction:</strong>Finally relevant features are identified and extracted from the images, such as vegitation indices, water bodeis, or urban areas.
              Texture analysis and spatially filtering are used for this purpose. </li>
              <li><strong>Change Detection: </strong>After going through all the above steps, multiple images over times are compared to idnetify changes in land cover or other features. 
              The algorithm is then trained using a training set which includes images from different geographical locations with similar characteristics. </li>
            </ol>

          <h3>Satellite data collection levels</h3>

          <p>Within remote sensing and its applications, there are a series of levels that are used to define the amount of processing that has been performed to provide a given dataset. 
            Satellite data is collected at various levels, each representing a different stage of processing and refinement. Here are the common levels of satellite data:</p>
          <ol>
            <li><strong>Level 0 (L0): Raw Data:</strong> This is the unprocessed, raw data directly from the satellite's sensors and refers to full resolution data. It includes unprocessed digital counts or voltage 
              measurements. L0 data is transmitted to ground stations. It is unlikely that we will work with this level of data, especially for more modern sensors, as this data lacks information 
              such as geo-referencing and time-referencing ancillary information.</li>

            <li><strong>Level 1 (L1): Radiometric Calibration:</strong> In this level, the raw data undergoes radiometric calibration, which involves correcting for sensor-specific 
              characteristics, such as sensor sensitivity and noise. This step aims to ensure that the data values are consistent and comparable over time.</li>

            <li><strong>Level 2 (L2): Geometric Correction:</strong> Geometric correction is applied to correct distortions caused by the Earth's terrain and the satellite's position. This includes corrections for 
              terrain relief, sensor viewing angle, and other geometric distortions, ensuring that the imagery accurately represents the Earth's surface.</li>

            <li><strong>Level 3 (L3): Atmospheric Correction:</strong> Atmospheric correction involves removing or correcting the effects of the Earth's atmosphere on the satellite data. This is crucial for 
              obtaining accurate surface reflectance values, especially in applications where the atmospheric conditions can affect the interpretation of features on the Earth's surface.</li>

            <li><strong>Level 4 (L4): Data Processing and Analysis:</strong> At this level, the data is processed and analyzed to generate higher-level products, such as thematic maps, classifications, or indices. 
              This level often involves the extraction of specific information from the satellite imagery, depending on the objectives of the remote sensing application.</li>
          </ol>
          <p>It's important to note that not all satellite data goes through all these levels. The processing levels that data undergoes depend on the specific requirements of the remote sensing application 
            and the type of data needed for analysis. Researchers and analysts choose the appropriate level of data based on the goals and objectives of their studies.</p>

          <figure style="text-align: center;">
            <img src="assets/img/remote-sensing/Level-0-4-stages.png" alt="" style="max-width: 90%; max-height: 90%;">
            <figcaption style="text-align: center;">Level-0 to Level-1 remote sensing data transformation. (<strong>Image credit: © </strong><a href="https://arunp77.github.io/Arun-Kumar-Pandey/" target="_blank"> Arun Kumar Pandey</a>)</figcaption>
          </figure>
        </section>

          <section id="Data-Transformation-required">
          <h3 id="Data-Transformation-required">Data Processing<a class="anchor-link" href="#Data-Transformation-required">&#182;</a></h3><p>Level 0 (L0) data represents 
            the raw, unprocessed data directly received from a satellite's sensors. Transforming Level 0 data into Level 1 and higher levels involves several essential steps to convert the raw 
            sensor measurements into physically meaningful units. Here's a step-by-step process for this transformation:</p>
            <figure style="text-align: center;">
              <img src="assets/img/remote-sensing/Level-0-4.png" alt="" style="max-width: 90%; max-height: 90%;">
              <figcaption style="text-align: center;"><strong>Image credit:</strong><a href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-36699-9_36">Processing Levels, 
                Ron Weaver </a></figcaption>
            </figure>
            
            <ul>
              <li><strong>Level-0 to Level-1 Transformation: </strong>
                <p>The transformation from level-0 to level-1 involves converting the raw sensor data into calibrated and corrected data. This process typically includes the following steps:</p>
                <ol>
                  <li><strong>Radiometric Calibration: </strong>This step converts the digital counts or voltages recorded by the sensor into physical units of radiance or reflectance. This is done by applying calibration coefficients that are determined during sensor calibration. The calibration coefficients account for the sensor's sensitivity and response to different wavelengths of radiation.
                    The digital counts (DN) recorded by Sentinel-2 sensors are converted to radiance (L) using the following equation:

                    $$L = (\text{DN}- \text{Offset})\times \text{Gain}$$

                    where,<br>
                    where <code>Offset</code> and <code>Gain</code> are calibration coefficients determined during sensor testing.
                  </li>
                  <li><strong>Sensor Correction: </strong>This step corrects for sensor-specific errors and non-linearities. This may involve removing sensor bias, correcting for non-linear responses, and applying gain corrections. The goal is to ensure that the sensor data accurately represents the incoming radiation.</li>
                  <li><strong>Geometric Correction: </strong>This step corrects for distortions caused by the sensor's optics and the earth's curvature. This is done by applying a geometric transformation to the data to align it with a reference map or coordinate system. The transformation accounts for factors such as sensor orientation, lens distortion, and earth's projection.
                    <div class="box">
                      <p>Geometric correction is performed using a variety of techniques, such as polynomial fitting, map projection, and terrain correction. The goal is to remove distortions caused by the sensor's optics and the earth's curvature and to align the data with a reference map or coordinate system. For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                      </p>
                    </div>
                  </li>
                  <li><strong>Geometric Registration: </strong>This step aligns multiple level-1 data sets to a common coordinate system. This is necessary for multi-temporal or multi-sensor analyses, where data from different sources or time periods needs to be compared or overlaid.
                    <div class="box">
                      It is performed by assigning geographic coordinates (latitude and longitude) to each pixel in the image. This is done by matching the image to a reference map or coordinate system. For more details see
                      <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                </ol>
              </li>
              <li><strong>Level-1 to Level-2 Transformation: </strong>
                <p>The transformation from level-1 to level-2 involves deriving physical properties of the earth's surface and atmosphere from the calibrated and corrected data. This process typically includes the following steps:</p>
                <ol>
                  <li><strong>Atmospheric Correction: </strong>This step removes the effects of the atmosphere on the level-1 data. This is done by modeling the interaction of radiation with the atmosphere, including scattering, absorption, and emission. The goal is to obtain a more accurate representation of the earth's surface reflectance.
                  <div class="box">
                    Atmospheric correction is performed using a variety of techniques, such as the Sen2Cor algorithm or the ACOLITE algorithm. The goal is to remove the effects of the atmosphere on the level-1 data to obtain a more accurate representation of the earth's surface reflectance.
                    For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                  </div>
                  </li>
                  <li><strong>Atmospheric Parameter Retrieval: </strong>This step retrieves atmospheric parameters, such as aerosol concentration, ozone concentration, and water vapor content, from the level-1 data. This is done using algorithms that analyze the spectral characteristics of the radiation.</li>
                  <li><strong>Surface Property Retrieval: </strong>This step derives physical properties of the earth's surface, such as land cover, vegetation cover, and water content, from the level-2 data. This is done using algorithms that analyze the spectral reflectance of the surface.
                    <div class="box">
                      Surface property retrieval is performed using a variety of algorithms, such as the normalized difference vegetation index (NDVI) algorithm or the land surface temperature (LST) retrieval algorithm. The goal is to derive physical properties of the earth's surface, such as land cover, vegetation cover, and water content, from the level-2 data.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Data Validation: </strong>This step ensures the quality and accuracy of the level-2 data. This involves checking for outliers, artifacts, and inconsistencies in the data.</li>
                </ol>
              </li>
              <li><strong>Level-2 to Level-3 Transformation: </strong>
                <p>The transformation from level-2 to level-3 involves integrating level-2 data into thematic maps or geophysical products. This process typically includes the following steps:</p>
                <ol>
                  <li><strong>Mosaicking: </strong>This step combines multiple level-2 data sets into a seamless mosaic. This is necessary for large-scale analyses, where data from different regions or time periods needs to be combined.
                    <div class="box">
                      Mosaicking is performed by combining multiple level-2 data sets into a seamless mosaic. This is necessary for large-scale analyses, where data from different regions or time periods needs to be combined.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Geolocation and Projection: </strong>This step assigns geographic coordinates (latitude and longitude) to the level-3 data and projects it onto a standard map projection. This allows the data to be accurately displayed and analyzed in a geographic context.
                    <div class="box">
                      Geolocation and projection are performed by assigning geographic coordinates and projecting the data onto a standard map projection. This allows the data to be accurately displayed and analyzed in a geographic context.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Thematic Mapping: </strong>This step generates thematic maps that represent specific themes or characteristics of the earth's surface. This may involve classifying land cover, identifying vegetation types, or mapping surface water bodies.
                    <div class="box">
                      Thematic mapping is performed by classifying each pixel in the image based on its spectral characteristics. This may involve classifying land cover, identifying vegetation types, or mapping surface water bodies.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Geophysical Product Generation: </strong>This step generates geophysical products, such as digital elevation models (DEMs) or land surface temperature maps. These products provide quantitative information about the earth's surface and atmosphere.</li>
                </ol>
              </li>
              <li><strong>Level-3 to Level-4 Transformation: </strong>
                <p>The transformation from Level-3 to Level-4 involves deriving higher-level information and insights from the thematic maps and geophysical products generated at Level-3. This process typically includes the following steps:</p>
                <ol>
                  <li><strong>Data Integration and Analysis: </strong>This step integrates multiple Level-3 data sets and other relevant information sources, such as ancillary data, climate models, and socio-economic data. This integration allows for a more comprehensive understanding of the Earth's system and its interactions.
                    <div class="box">
                      Data integration and analysis involves integrating multiple Level-3 data sets and other relevant information sources, such as ancillary data, climate models, and socio-economic data. This integration allows for a more comprehensive understanding of the Earth's system and its interactions
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Change Detection and Characterization: </strong>This step identifies and characterizes changes in the Earth's system over time. This may involve analyzing trends in land cover, vegetation cover, or water resources, or detecting and monitoring deforestation, urbanization, or natural disasters.
                    <div class="box">
                      Change detection and characterization involves identifying and characterizing changes in the Earth's system over time. This may involve analyzing trends in land cover, vegetation cover, or water resources, or detecting and monitoring deforestation, urbanization, or natural disasters.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Modeling and Simulation: </strong>This step develops models to simulate the behavior of the Earth's system and predict future trends. This may involve using climate models, land use models, or hydrological models to understand and anticipate changes in the environment.
                    <div class="box">
                      Modeling and simulation involves developing models to simulate the behavior of the Earth's system and predict future trends. This may involve using climate models, land use models, or hydrological models to understand and anticipate changes in the environment.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Uncertainty Assessment: </strong>This step quantifies the uncertainty associated with Level-3 and Level-4 data products. This is important for understanding the limitations and reliability of the information and for making informed decisions based on the data.
                    <div class="box">
                      Uncertainty assessment involves quantifying the uncertainty associated with Level-3 and Level-4 data products. This is important for understanding the limitations and reliability of the information and for making informed decisions based on the data.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                  <li><strong>Decision Support: </strong>This step provides decision-makers with actionable insights derived from Level-3 and Level-4 data. This may involve developing recommendations for sustainable land use practices, disaster preparedness strategies, or climate change adaptation plans.
                    <div class="box">
                      Decision support involves providing decision-makers with actionable insights derived from Level-3 and Level-4 data. This may involve developing recommendations for sustainable land use practices, disaster preparedness strategies, or climate change adaptation plans.
                      For more details see
                        <a href="Remote-sesning-image-processing.html">Remote sensing image processing page</a>.
                    </div>
                  </li>
                </ol>
              </li>
              <p>The Level-3 to Level-4 transformation represents a critical step in converting raw remote sensing data into actionable information that can be used to address environmental challenges, support sustainable development, and inform decision-making processes.</p>
              <p>The transformation of level-0 data to level-4 data is a complex process that involves a series of mathematical operations and algorithms. The specific equations and techniques used will depend on the type of sensor, the earth's surface features, and the atmospheric conditions. However, the general principles of calibration, correction, geolocation, atmospheric correction, surface property retrieval, thematic mapping, and geophysical product generation are applicable to most remote sensing data processing workflows.</p>
            </ul>
          </section>

            <section id="Voltage-values-in-Level-0-data">
            <h3>Voltage values in Level-0 data</h3>
              <p>In the context of collecting raw data from satellite sensors, "voltage values" refer to one of the ways that certain types of sensors record measurements. 
                When a sensor detects a physical quantity, such as light intensity or temperature, it often generates an electrical signal proportional to that quantity. 
                This electrical signal is typically in the form of voltage.</p>
              <p>Here's a more detailed explanation:</p>
              <ol>
                <li><p><strong>Sensor Output:</strong> Satellite sensors are designed to capture various types of data, such as imagery, temperature, or radiation levels. 
                  When these sensors interact with the environment, they produce an electrical signal that corresponds to the measured quantity.</p>
                </li>
                <li><p><strong>Voltage as a Signal:</strong> In many cases, this electrical signal is in the form of voltage. The magnitude of the voltage signal is directly 
                  related to the quantity being measured. For example, in an optical sensor, the amount of light detected can be translated into a voltage signal where higher 
                  light intensity corresponds to higher voltage values.</p>
                </li>
                <li><p><strong>Analog-to-Digital Conversion:</strong> Before transmitting the data, the analog voltage signal is often converted into a digital representation. 
                  This process is called analog-to-digital conversion (ADC). In ADC, the continuous analog voltage is sampled at discrete intervals and assigned digital values 
                  (digital counts).</p>
                </li>
                <li><p><strong>Digital Counts:</strong> These digital values, referred to as "digital counts" or simply "counts," are then transmitted as part of the raw data. 
                  Each count represents a specific voltage level recorded by the sensor during its measurement.</p>
                </li>
              </ol>
              <p>For instance, if you have an optical sensor on a satellite that measures sunlight intensity, it might generate voltage values as it detects varying levels 
                of sunlight. These voltage values are then digitized and transmitted as part of the raw data to ground stations or receivers for further processing and analysis.</p>
              <p>In summary, "voltage values" in this context refer to the electrical signals generated by satellite sensors to represent the physical quantities they are 
                designed to measure. These signals are converted into digital counts for transmission and subsequent data processing.</p>

                <h3>Reflectance</h3>

                <figure style="text-align: center;">
                  <img src="assets/img/portfolio/spectrum-1.png" alt="" style="max-width: 90%; max-height: 90%;">
                </figure>

              Reflectance in remote sensing is calculated by measuring the amount of electromagnetic radiation (light) that is reflected from a surface. The reflectance values are 
              typically expressed as a percentage or a unitless fraction. The formula for calculating reflectance is as follows:
              $$\text{Reflectance} = \frac{\text{Reflected Radiance}}{\text{Incident Radiance}} \times 100\%$$

              where:
              <ul>
                <li><strong>Reflectance: </strong>The percentage of light that is reflected by a surface. It indicates how much of the incident light is returned.</li>
                <li><strong>Reflected Radiance: </strong>The amount of electromagnetic radiation (light) that is reflected by the surface and measured by the sensor. It is often 
                  represented in radiance units. </li>
                <li><strong>Incident Radiance: </strong>The amount of electromagnetic radiation (light) that reaches the surface. It is the incoming light before interacting with the surface.</li>
              </ul>
              <p>Reflectance values range from 0% (no reflection) to 100% (complete reflection). A reflectance of 0% indicates that the surface absorbs all incident light, while a 
                reflectance of 100% means that the surface reflects all incident light.</p>
              <p>In practice, the reflectance values are often corrected for atmospheric effects and sensor characteristics. The reflectance calculation is an essential step in 
                converting raw remote sensing data into meaningful information that can be used for various applications, such as land cover classification, vegetation health 
                assessment, and environmental monitoring.</p>
              <p>The accuracy of reflectance calculations depends on factors such as sensor calibration, atmospheric correction, and the spectral characteristics of the surface 
                being observed. Remote sensing instruments equipped with different spectral bands capture the reflected radiance at specific wavelengths, allowing scientists to 
                analyze and interpret the Earth's surface properties.</p>

              <h3><strong>Spectral Indices in Remote Sensing</strong></h3>
              <p>Spectral indices in remote sensing are mathematical combinations of reflectance values from different spectral bands. These indices help highlight specific 
                features or characteristics of the Earth's surface, such as vegetation health, water content, or soil moisture.
                <figure style="text-align: center;">
                  <img src="assets/img/remote-sensing/spectral-indexes-1.png" alt="" style="max-width: 80%; max-height: 80%;">
                  <figcaption style="text-align: center;"> Spectral indices mini cubes computed from Sentinel-2 displaying a 2.56 km radius around the DE-Hai
                    site (<a href="https://www.nature.com/articles/s41597-023-02096-0" target="_blank"> <strong>Image credit: </strong> Reference paper by David Montero et. al.</a>)</figcaption>
                </figure>

                Here are a few commonly used spectral indices:</p>
              <ol>
                <li><strong>Normalized Difference Vegetation Index (NDVI):</strong><br>
                  (For reference, please see the link <a href="https://www.sciencedirect.com/topics/earth-and-planetary-sciences/normalized-difference-vegetation-index" target="_blank">Normalized Difference Vegetation Index</a>)
                  <figure style="text-align: center;">
                    <img src="assets/img/remote-sensing/NDVI.png" alt="" style="max-width: 90%; max-height: 90%;">
                  </figure>
                  <ul>
                    <li><strong>Formula: </strong>
                      $$\text{NDVI} = \frac{(\text{NIR} - \text{Red})}{(\text{NIR}+\text{Red})}$$
                    <li><strong>Purpose: </strong> NDVI is widely used to assess vegetation health and density. Healthy vegetation reflects more near-infrared (NIR) light and 
                      absorbs more red light.s</li>
                    <li>NIR (Near-Infrared): Reflectance in the near-infrared region of the electromagnetic spectrum.</li>
                    <li>Red: Reflectance in the red region of the electromagnetic spectrum.</li>
                  </ul>
                </li>
                <li><strong>Enhanced Vegetation Index (EVI):</strong>
                  <ul>
                    <li><strong>Formula: </strong>
                      $$\text{EVI} = G\times \frac{(\text{NIR} - \text{Red})}{(\text{NIR}+C_1 \times \text{Red}-C_2 \times \text{Blue}+L)}$$
                    </li>
                    <li><strong>Purpose: </strong>EVI is an enhanced version of NDVI, designed to minimize atmospheric influences and improve sensitivity to vegetation.</li>
                    <li>G (Gain Factor): A gain factor to optimize the sensitivity of the index.</li>
                    <li>C1, C2 (Coefficients): Coefficients to correct for aerosol influences.</li>
                    <li>L (Canopy background adjustment): Canopy background adjustment to minimize soil background influences.</li>
                  </ul>
                </li>
                <li><strong>Normalized Difference Water Index (NDWI):</strong>
                  <ul>
                    <li><strong>Formula: </strong>
                      $$\text{NDWI} = \frac{(\text{Green} - \text{NIR})}{(\text{Green}+\text{NIR})}$$
                    </li>
                    <li><strong>Purpose: </strong>NDWI is used to detect the presence of water. Water absorbs more in the near-infrared region, resulting in a lower reflectance value.</li>
                    <li>Green: Reflectance in the green region of the electromagnetic spectrum.</li>
                  </ul>
                </li>
                <li><strong>Soil Adjusted Vegetation Index (SAVI):</strong>
                  <ul>
                    <li><strong>Formula: </strong>
                      $$\text{SAVI} = (1+L)\times \frac{(\text{NIR} - \text{Red})}{(\text{NIR}+\text{Red}+L)}$$
                    </li>
                    <li><strong>Purpose: </strong>SAVI is designed to reduce the influence of soil brightness on vegetation indices, making it useful in areas with varying soil conditions.</li>
                    <li>L (Soil adjustment factor): A soil adjustment factor to reduce the influence of soil brightness.</li>
                  </ul>
                </li>
                <li><strong>Normalized Burn Ratio (NBR):</strong>
                  <ul>
                    <li><strong>Formula: </strong>
                      $$\text{NBR} = \frac{(\text{NIR} - \text{SWIR})}{(\text{NIR}+\text{SWIR})}$$
                    </li>
                    <li><strong>Purpose: </strong>NBR is used for post-fire assessment, as it highlights changes in vegetation cover and health after a fire.</li>
                    <li>SWIR (Shortwave Infrared): Reflectance in the shortwave infrared region of the electromagnetic spectrum.</li>
                  </ul>
                </li>
                <li><strong>Moisture Stress Index (MSI):</strong>
                  <ul>
                    <li><strong>Formula: </strong>
                      $$\text{NBR} = \frac{(\text{NIR} - \text{SWIR})}{(\text{NIR}+\text{SWIR})}$$
                    </li>
                    <li><strong>Purpose:</strong> MSI helps identify areas experiencing moisture stress by leveraging differences in water absorption in the near-infrared and shortwave infrared regions.</li>
                  </ul>
                </li>
              </ol>
              <p>These indices are calculated using the reflectance values from specific spectral bands, often captured by satellite or airborne sensors. 
              By applying these indices, remote sensing analysts can extract valuable information about the environment, monitor changes, and gain insights into various ecological and agricultural parameters.</p><br>

              <h3>Remote Sensing – Spectral Indices – Applications</h3>
              <p>Remote sensing and spectral indices have various applications, especially in the realm of data science and analytics. Spectral indices are mathematical calculations applied to remote sensing data to extract meaningful information. Some applications include:</p>
              <ol>
                <li>Vegetation Monitoring: Spectral indices like NDVI (Normalized Difference Vegetation Index) are widely used to assess vegetation health and monitor changes over time.</li>
                <li>Crop Health Assessment: Remote sensing helps in evaluating crop conditions, detecting diseases, and optimizing agricultural practices using indices such as NDVI or EVI (Enhanced Vegetation Index).</li>
                <li>Land Cover Classification: Spectral indices contribute to accurate land cover mapping, aiding in urban planning, environmental monitoring, and resource management.</li>
                <li>Water Quality Monitoring: Spectral indices can be employed to assess water quality in lakes, rivers, and oceans by detecting changes in water properties.</li>
                <li>Forest Management: Remote sensing assists in forest inventory, monitoring deforestation, and assessing overall forest health using indices tailored for vegetation analysis.</li>
                <li>Climate Change Studies: Spectral indices contribute to monitoring environmental changes, such as shifts in temperature, precipitation, and vegetation patterns, supporting climate change research.</li>
                <li>Disaster Management: Remote sensing helps in assessing and managing natural disasters like floods, wildfires, and earthquakes by providing real-time data for decision-making.</li>
              </ol>

<p>In the context of your interests in data science, analytics, and data engineering, integrating and analyzing remote sensing data using the mentioned tools and technologies can enhance insights and support decision-making in these domains.</p>


              <h3><span style="color:red"><strong>Radiance or Reflectance:</strong></span></h3>
              <p>Radiance and reflectance are two fundamental radiometric quantities used in remote sensing and satellite imagery to describe the properties of the reflected 
                or emitted electromagnetic radiation from surfaces on Earth. These quantities are used to quantify the amount of light or radiation observed by remote sensing 
                sensors. Here's an explanation of each, along with their formulas:</p>
              <ol>
                <li><strong>Radiance (L):</strong>
                  <ul>
                    <li><strong>Definition:</strong> Radiance measures the amount of electromagnetic radiation per unit 
                      area, per unit solid angle, and per unit wavelength interval. It describes the radiative energy 
                      received by a sensor from a particular direction and wavelength.</li>
                    <li><strong>Units:</strong> Radiance is typically expressed in watts per square meter per 
                      steradian per micrometer (W/(m²·sr·μm)).</li>
                    <li><strong>Formula:</strong> The formula for radiance is given by:
                    
                      \[L(\lambda) = \frac{\pi \cdot R(\lambda)}{E(\lambda)}\]
                      
                      <p>where:</p>
                        <ul>
                          <li>L(λ) is the radiance at wavelength λ.</li>
                          <li>R(λ) is the radiance received by the sensor from the target.</li>
                          <li>E(λ) is the effective spectral radiance of the sensor.</li>
                        </ul>
                    </li>
                  </ul><br>
                  <div style="background-color: #66a8a56b; padding: 15px; border-radius: 5px; border: 1px solid #000;">
                      <p>In the case of satellite measurments, the objective of ocean sensors is to retreive the spectral distribution of upwelling radiance 
                        just above the sea surface, which is termed the water leaving radiance (L<sub>w</sub>). However, the sensors actually measure the Top 
                        of Atmoshphere (TOA) radiance L<sub>t</sub> and so the contribution resulting from processes such as the atmosphere such as the 
                        atmoshphere's scattering and absorption needs to be accounted for -termed Atmospheric  Correction (AC).

                    $$L_t(\lambda) = L_r(\lambda)+ L_a(\lambda)+L_{ra}(\lambda)+t(\lambda)L_{wc}(\lambda)+T(\lambda)L_{g}(\lambda)+t(\lambda)t_0(\lambda)\text{cos}(\theta_0)
                    L_{wn}(\lambda)$$

                    where</p>
                    
                    <ul>
                    <li>L<sub>r</sub> due to Rayleigh scattering</li>
                    <li>L<sub>a</sub> due to aerosol scattering</li>
                    <li>L<sub>ra</sub> due to interaction aerosols and molecules</li>
                    <li>L<sub>wc</sub> due to interaction between white caps</li>
                    <li>L<sub>g</sub> due to  interaction between  glint.</li>
                    <li>t and t<sub>0</sub> are diffusive transmmitances of the atmohsphere from the surface to the senor and from the sun to the surface.</li>
                    <li>T is the direct transmittance from surface to sensor</li>
                    <li> θ<sub>0</sub> is the solar zenith angle </li>
                    <li>L<sub>wn</sub>(λ) is the normalized water leaving radiance.</li>
                    </ul>
                  </div><br>

                <li><strong>Reflectance (ρ) or Reflectance Factor (RF):</strong>
                  <ul>
                    <li><strong>Definition:</strong> Reflectance measures the ratio of reflected light from a surface to the incident light upon it. It quantifies how much of 
                      the incoming radiation is reflected by the surface. Reflectance is usually expressed as a dimensionless value between 0 and 1, but it can be multiplied 
                      by 100 to express it as a percentage.</li>
                    <li><strong>Units:</strong> Reflectance is a dimensionless quantity or percentage.</li>
                    <li><strong>Formula:</strong> The formula for reflectance is given by:
                    $$
                    \rho(\lambda) = \frac{L_{\rm reflected(\lambda)}}{L_{\rm incident(\lambda)}}
                    $$
                    where:
                    <ul>
                      <li>ρ(λ) is the reflectance at wavelength λ.</li>
                      <li>L<sub>reflected</sub>(λ) is the radiance of the reflected light from the target.</li>
                      <li>L<sub>incident</sub>(λ) is the radiance of the incident light on the target.</li>
                    </ul>
                  </ul>
              </ol>
              <p>The calculation of reflectance often involves radiometric calibration to convert sensor radiance measurements to physical units and account for atmospheric 
                effects. Reflectance is an important quantity in remote sensing because it allows for the comparison of data collected by different sensors or at different 
                times, making it a valuable tool for monitoring changes in land cover, vegetation health, and other Earth surface properties.</p>
              <p>Note that the specific calculation of reflectance can be more complex in practice, taking into account various factors like atmospheric correction, sensor 
                characteristics, and surface properties. The formula provided here is a simplified representation, and in practice, detailed algorithms and corrections may 
                be applied to obtain accurate reflectance values from remote sensing data.</p>
              <p>(Reference: <a href="https://training.eumetsat.int/mod/book/tool/print/index.php?id=11832">https://training.eumetsat.int/mod/book/tool/print/index.php?id=11832</a>)</p>
            </section>

              <h2>Calculation of physical parameters from the Radiance:</h2>

              <p>Once you have preprocessed raw data received from a remote sensing satellite and calculated radiance, you can use this radiance data to derive several 
                important physical parameters and information about the Earth's surface and atmosphere. The specific parameters you can calculate depend on the type of 
                remote sensing data, the spectral bands used, and the sensors' characteristics. Here are some common physical parameters that can be derived from radiance data:</p>

              <ol>
                  <li><strong>Surface Temperature:</strong>
                      <ul>
                          <li>Radiance data in thermal infrared bands can be used to calculate the surface temperature of the Earth's features. This is essential for 
                            applications like land surface temperature monitoring, agriculture, and urban heat island analysis.</li>
                      </ul>
                  </li>
                  
                  <li><strong>Vegetation Indices:</strong>
                      <ul>
                          <li>Radiance data in visible and near-infrared bands can be used to calculate vegetation indices such as the Normalized Difference Vegetation 
                            Index (NDVI) or Enhanced Vegetation Index (EVI). These indices provide information about vegetation health, density, and vigor.</li>
                      </ul>
                  </li>

                  <li><strong>Ocean Color Parameters:</strong>
                      <ul>
                          <li>Radiance data over water bodies can be used to calculate ocean color parameters such as chlorophyll-a concentration, water turbidity, and 
                            suspended particulate matter. These parameters are crucial for marine and coastal studies.</li>
                      </ul>
                  </li>

                  <li><strong>Aerosol Optical Depth (AOD):</strong>
                      <ul>
                          <li>Radiance data can be used to estimate the AOD, which quantifies the amount of aerosols (dust, smoke, pollution) in the atmosphere. AOD is 
                            vital for studying air quality, climate modeling, and visibility assessments.</li>
                      </ul>
                  </li>

                  <li><strong>Atmospheric Profiles:</strong>
                      <ul>
                          <li>Radiance data can be used in conjunction with radiative transfer models to derive vertical profiles of atmospheric parameters, including 
                            temperature, humidity, and aerosol content. These profiles are valuable for atmospheric research and weather forecasting.</li>
                      </ul>
                  </li>

                  <li><strong>Snow Cover and Albedo:</strong>
                      <ul>
                          <li>Radiance data can be used to estimate snow cover extent and calculate surface albedo, which measures the reflectivity of the Earth's surface. 
                            These parameters are essential for climate studies and snowmelt modeling.</li>
                      </ul>
                  </li>

                  <li><strong>Land Surface Emissivity:</strong>
                      <ul>
                          <li>For thermal infrared data, you can calculate land surface emissivity, which is essential for accurate surface temperature retrieval and energy 
                            balance studies.</li>
                      </ul>
                  </li>

                  <li><strong>Land Cover Classification:</strong>
                      <ul>
                          <li>Radiance data can be used for land cover classification and land use mapping, providing information on the types of land features present in a 
                            particular area.</li>
                      </ul>
                  </li>

                  <li><strong>Cloud Properties:</strong>
                      <ul>
                          <li>Radiance data can be used to retrieve cloud properties such as cloud height, cloud type, and cloud cover fraction. This information is vital 
                            for weather forecasting and climate studies.</li>
                      </ul>
                  </li>

                  <li><strong>Surface Roughness:</strong>
                      <ul>
                          <li>Radiance data can be used to estimate surface roughness, which is useful for applications like agriculture, hydrology, and soil moisture monitoring.</li>
                      </ul>
                  </li>
              </ol>

              <p>It's important to note that the process of deriving these physical parameters often involves complex radiative transfer models, atmospheric correction, and 
                calibration procedures. Additionally, the availability of specific bands and sensors on the remote sensing satellite can impact the types of parameters that 
                can be calculated. Therefore, the choice of satellite and sensor should align with the specific objectives of your remote sensing analysis.</p>

              <h3>Calculation of surface temperature:</h3>

                <p>Surface temperature is often calculated using radiance data acquired in the thermal infrared (TIR) spectral range. The process involves several steps, 
                  including atmospheric correction and radiative transfer modeling. Here's an overview of how surface temperature is calculated from radiance data:</p>

                <ol>
                    <li><strong>Radiance Measurement:</strong>
                        <ul>
                            <li>Radiance data is collected by remote sensing instruments operating in the TIR spectral range. These sensors capture the thermal radiation 
                              emitted by the Earth's surface in the form of radiance values.</li>
                        </ul>
                    </li>
                    
                    <li><strong>Atmospheric Correction:</strong>
                        <ul>
                            <li>Atmospheric correction is a critical step because the atmosphere absorbs and scatters thermal radiation. To calculate surface temperature 
                              accurately, you need to remove the atmospheric effects. This is typically done using radiative transfer models or atmospheric profile data.</li>
                        </ul>
                    </li>

                    <li><strong>Emissivity Correction:</strong>
                        <ul>
                            <li>Surface emissivity is a measure of how efficiently a surface emits thermal radiation. It can vary depending on the material and the wavelength 
                              of observation. To calculate surface temperature, you need to know or estimate the emissivity of the surface in the TIR band. Emissivity values 
                              are typically assigned based on land cover classes or measured in the field.</li>
                        </ul>
                    </li>

                    <li><strong>Planck's Law:</strong>
                        <ul>
                            <li>Planck's law describes the relationship between radiance, temperature, wavelength, and emissivity. It is used to relate the radiance measured 
                              by the sensor to the surface temperature and emissivity. The formula for Planck's law is:</li>
                        </ul>
                        <img src="https://latex.codecogs.com/svg.latex?L%28%5Clambda%2C%20T%29%20%3D%20%5Cfrac%7B2%20%5Cpi%20h%20c%5E2%7D%7B%5Clambda%5E5%7D%20%5Cfrac%7B1%7D%7Be%5E%7B%5Cfrac%7Bhc%7D%7B%5Clambda%20k%20T%7D%7D%20-1%7D">
                    </li>

                    <li><strong>Iterative Optimization:</strong>
                        <ul>
                            <li>Calculating surface temperature from radiance data involves an iterative optimization process. Given the measured radiance, known or estimated 
                              emissivity, and the Planck's law equation, an iterative optimization algorithm is used to find the temperature that best fits the observed radiance. 
                              This is typically done for each pixel in the image.</li>
                        </ul>
                    </li>

                    <li><strong>Output:</strong>
                        <ul>
                            <li>The result of this process is a surface temperature map, where each pixel represents the estimated temperature of the corresponding area on 
                              the Earth's surface.</li>
                        </ul>
                    </li>
                </ol>

                <p>It's important to note that accurate surface temperature retrieval can be influenced by various factors, including atmospheric conditions, sensor 
                  characteristics, and emissivity assumptions. Therefore, careful calibration, validation, and consideration of these factors are essential to ensure 
                  the reliability of the calculated surface temperatures in remote sensing applications.</p>


                <h4>Note:</h4>

                <ul>
                    <li><strong>Power/Radiation Flux:</strong> The rate at which energy is transferred per time t is known as power: 
                      $$P = \frac{dQ}{dt} ~~~~[J s^{-1}] = W$$.
                        <ul>
                            <li>When speaking about radiant power that is emitted by, passing through, or incident on a particular surface, the term flux ϕ is more commonly used.</li>
                        </ul>
                    </li>
                
                    <li><strong>Flux Density:</strong> The term flux density E refers to the spatial density of radiant power. It is defined as the infinitesimal amount 
                      of radiant power 
                      <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mi>&#x03C6;</mi><mo>(</mo><mi>&#x1D431;</mi><mo>,</mo><mi>&#x1D714;</mi><mo>)</mo></mrow></math>
                      passing through an infinitesimal surface element dA that is aligned normal to a direction θ
                      and located at a position <math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi>r</mi><mo>&rarr;</mo></mover></math> of interest.
                        
                            $$dE(\vec{r}, \vec{\theta}) = \frac{d\phi(\vec{r}, \vec{\theta})}{dA}~~~ [W m^{-2}]$$

                    </li>
                
                    <li><strong>Radiance:</strong> The radiance, i.e., a measure of the radiant intensity that originates from a small unit area <d>dA</d><sup>&perp;</sup>
                      (aligned normal to the direction θ of interest) rather than from a single point:
                        
                        $$L(\vec{r}, \vec{\theta}) = \frac{d\phi^2(\vec{r}, \vec{\theta})}{dA^\perp d\Omega}$$
                        
                    </li>
                </ul>
                
                <img src="assets/img/portfolio/image-8.png" alt="Your Image" style="max-width: 500px;"/>
                
                <p>The quantity radiance is a quantity that is characteristic for a specific point <math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi>r</mi><mo>&rarr;</mo></mover></math>
                   and a direction θ. It is defined as the amount of flux passing through a unit area <d>A</d><sup>&perp;</sup> (centered at <math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi>r</mi><mo>&rarr;</mo></mover></math> and aligned normal to θ) into a solid angle Ω around the direction of θ.</p>
                
                <p>(Reference: <a href="https://www.physics-in-a-nutshell.com/article/22/local-properties-of-radiation">https://www.physics-in-a-nutshell.com/article/22/local-properties-of-radiation</a>)</p>
                
              <!----------------  Reference ------------>
              <h3>Reference:</h3>
                <ul style="margin-left: 30px;">
                  <li><a href="https://www.mdpi.com/2072-4292/12/16/2597" target="_blank">Evaluation Analysis of Landsat Level-1 and Level-2 Data Products Using In Situ Measurements, Cibele Teixeira Pinto, Xin Jing, Larry Leigh.</a></li>
                  <li><a href="https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing">Earthdata NASA - Remote Sensing</a></li>
                  <li><a href="https://en.wikipedia.org/wiki/Remote_sensing">Wikipedia - Remote Sensing</a></li>
                  <li><a href="https://giovanni.gsfc.nasa.gov/giovanni/#service=DiArAvTs&starttime=2022-01-01T00:00:00Z&endtime=2023-01-31T23:59:59Z&bbox=68.1152,5.8337,96.416,37.4744&data=OMAERUVd_003_FinalAerosolAbsOpticalDepth388%2COMAERUVd_003_FinalAerosolAbsOpticalDepth500&variableFacets=dataProductObservation%3AModel%2CObservation%3B">Giovanni NASA</a></li>
                  <li><a href="https://appliedsciences.nasa.gov/get-involved/training/english/arset-satellite-data-air-quality-environmental-justice-and-equity">NASA Applied Sciences - Satellite Data</a></li>
                  <li><a href="https://en.wikipedia.org/wiki/European_Organisation_for_the_Exploitation_of_Meteorological_Satellites">Wikipedia - European Organisation for the Exploitation of Meteorological Satellites</a></li>
                  <li><a href="https://www.atmospheremooc.org/">Atmosphere MOOC</a></li>
                  <li><a href="https://www.eumetsat.int/online-learning">EUMETSAT Online Learning</a></li>
                  <li><a href="https://www.eumetsat.int/data-and-user-support/training">EUMETSAT Data and User Support - Training</a></li>
                  <li><a href="https://login.ltpy.adamplatform.eu/authentication/login/?next=/">ADAM Platform Login</a></li>
                  <li><a href="https://www.mdpi.com/1424-8220/19/20/4453" target="_blank">Multispectral Sensor Calibration and Characterization for sUAS Remote Sensing, by Baabak Mamaghani and Carl Salvaggio </a></li>
                  <li><a href="https://www.mdpi.com/2072-4292/12/16/2597" target="_blank">Evaluation Analysis of Landsat Level-1 and Level-2 Data Products Using In Situ Measurements</a></li>
                </ul>

                <div class="navigation">
                    <a href="index.html" class="clickable-box">
                        <span class="arrow-left">Go home</span>
                    </a>
                    <a href="Remote-sesning-image-processing.html" class="clickable-box">
                        <span class="arrow-right">Image processing</span>
                    </a>
                </div>
            </div>
        </div>
    </section><!-- End Portfolio Details Section -->

</main><!-- End #main -->

<!-- ======= Footer ======= -->
<footer id="footer">
  <div class="container">
    <div class="copyright">
      &copy; Copyright <strong><span>Arun</span></strong>
    </div>
  </div>
</footer><!-- End  Footer -->

<a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

<!-- Vendor JS Files -->
<script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
<script src="assets/vendor/typed.js/typed.umd.js"></script>
<script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    hljs.initHighlightingOnLoad();
  });
</script>

</body>

</html>