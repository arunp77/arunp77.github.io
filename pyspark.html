<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Pyspark</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/Favicon-1.png" rel="icon">
  <link href="assets/img/Favicon-1.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <!-- Creating a python code section-->
  <link rel="stylesheet" href="assets/css/prism.css">
  <script src="assets/js/prism.js"></script>

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- To set the icon, visit https://fontawesome.com/account-->
  <script src="https://kit.fontawesome.com/5d25c1efd3.js" crossorigin="anonymous"></script>
  <!-- end of icon-->

  <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

    <!-- ======= Header ======= -->
    <header id="header">
    <div class="d-flex flex-column">
        <div class="profile">
            <img src="assets/img/myphoto.jpeg" alt="" class="img-fluid rounded-circle">
            <h1 class="text-light"><a href="index.html">Arun</a></h1>
            <div class="social-links mt-3 text-center">
                <a href="https://www.linkedin.com/in/arunp77/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
                <a href="https://github.com/arunp77" class="github"><i class="bx bxl-github"></i></a>
                <a href="https://twitter.com/arunp77_" class="twitter"><i class="bx bxl-twitter"></i></a>
                <a href="https://www.instagram.com/arunp77/" class="instagram"><i class="bx bxl-instagram"></i></a>
                <a href="https://arunp77.medium.com/" class="medium"><i class="bx bxl-medium"></i></a>
            </div>
        </div>

        <nav id="navbar" class="nav-menu navbar">
            <ul>
                <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
                <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
                <li><a href="index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
                <li><a href="index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
                <li><a href="index.html#skills-and-tools" class="nav-link scrollto"><i class="bx bx-wrench"></i> <span>Skills and Tools</span></a></li>
                <li><a href="index.html#services" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Services</span></a></li>
                <li><a href="index.html#professionalcourses" class="nav-link scrollto"><i class="bx bx-book-alt"></i> <span>Professional Certification</span></a></li>
                <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-news"></i> <span>Publications</span></a></li>
                <li><a href="index.html#extra-curricular" class="nav-link scrollto"><i class="bx bx-rocket"></i> <span>Extra-Curricular Activities</span></a></li>
                <li><a href="index.html#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
            </ul>
        </nav><!-- .nav-menu -->
    </div>
    </header><!-- End Header -->

    <main id="main">
        <!-- ======= Breadcrumbs ======= -->
        <section id="breadcrumbs" class="breadcrumbs"> 
          <div class="container">
    
            <div class="d-flex justify-content-between align-items-center">
              <h2>Data Engineering</h2>
              <ol>
                <li><a href="Data-engineering.html" class="clickable-box">Content section</a></li>
                <li><a href="index.html#portfolio" class="clickable-box">Portfolio section</a></li>
              </ol>
            </div>
    
          </div>
        </section><!-- End Breadcrumbs -->

        <!------  right dropdown menue ------->
        <div class="right-side-list">
            <div class="dropdown">
                <button class="dropbtn"><strong>Shortcuts:</strong></button>
                <div class="dropdown-content">
                    <ul>
                        <li><a href="cloud-compute.html"><i class="fas fa-cloud"></i> Cloud</a></li>
                        <li><a href="AWS-GCP.html"><i class="fas fa-cloud"></i> AWS-GCP</a></li>
                        <li><a href="amazon-s3.html"><i class="fas fa-cloud"></i> AWS S3</a></li>
                        <li><a href="ec2-confi.html"><i class="fas fa-server"></i> EC2</a></li>
                        <li><a href="Docker-Container.html"><i class="fab fa-docker" style="color: rgb(29, 27, 27);"></i> Docker</a></li>
                        <li><a href="Jupyter-nifi.html"><i class="fab fa-python" style="color: rgb(34, 32, 32);"></i> Jupyter-nifi</a></li>
                        <li><a href="snowflake-task-stream.html"><i class="fas fa-snowflake"></i> Snowflake</a></li>
                        <li><a href="data-model.html"><i class="fas fa-database"></i> Data modeling</a></li>
                        <li><a href="sql-basics.html"><i class="fas fa-table"></i> QL</a></li>
                        <li><a href="sql-basic-details.html"><i class="fas fa-database"></i> SQL</a></li>
                        <li><a href="Bigquerry-sql.html"><i class="fas fa-database"></i> Bigquerry</a></li>
                        <li><a href="scd.html"><i class="fas fa-archive"></i> SCD</a></li>
                        <li><a href="sql-project.html"><i class="fas fa-database"></i> SQL project</a></li>
                            <!-- Add more subsections as needed -->
                    </ul>
                </div>
            </div>
        </div>

        <!-- ======= Portfolio Details Section ======= -->
        <section id="portfolio-details" class="portfolio-details">
        <div class="container">
            <div class="row gy-4">
                <h1>Apache Pyspark</h1>
                <div class="col-lg-8">
                    <div class="portfolio-details-slider swiper">
                        <div class="swiper-wrapper align-items-center"> 
                            <figure>
                            <img src="assets/img/data-engineering/Apache_Spark_logo.svg.png" alt="" style="max-width: 50%; max-height: auto;">
                            <figcaption></figcaption>
                            </figure>
                        </div>
                        <div class="swiper-pagination"></div>
                    </div>
                </div>

                <div class="col-lg-4 grey-box">
                    <div class="section-title">
                        <h3>Table of Contents</h3>
                        <ol>
                            <li><a href="#introduction">Introduction to Apache Spark</a></li>
                            <li><a href="#how-it-works">How does Spark work?</a></li>
                            <ul>
                                <li><a href="#difference">Difference between Hadoop and Apache Spark</a></li>
                                <li><a href="#key-concept">Some key concepts of Apache Spark</a></li>
                                <li><a href="#key-features">Key Features</a></li>
                            </ul>
                            <li><a href="#Components">Components of Apache Spark</a></li>
                            
                            <li><a href="#reference">Reference</a></li>
                        </ol>
                    </div>
                </div>
            </div>

            <section>
            <h3 id="introduction">Introduction to Apache pySpark</h3>
            PySpark is the Python API for Apache Spark, an open-source, distributed computing framework designed for large-scale data processing. It allows you to leverage the power of Spark from the familiar and approachable Python environment.
            It provides Python bindings that allow developers to create, test, and deploy applications using the Spark API. 

            <h5>Capabilities</h5>
            <ul>
                <li>Large-scale Data Processing: Efficiently handle massive datasets across distributed clusters.</li>
                <li>Fault Tolerance: Built-in mechanisms to handle node failures and ensure job completion.</li>
                <li>Structured, Semi-structured, and Unstructured Data Support: Work with various data formats like CSV, JSON, XML, and text files.</li>
                <li>SQL-like Queries: Utilize Spark SQL for familiar data analysis using SQL syntax.</li>
                <li>Machine Learning: Build and train various machine learning models with Spark MLlib.</li>
                <li>Real-time Data Processing: Analyze streaming data with Spark Streaming.</li>
            </ul>


            <h5>Key Components</h5>
            <ul>
                <li><strong>SparkContext:</strong> Entry point for interacting with Spark, managing cluster connections and resources.</li>
                <li><strong>Resilient Distributed Datasets (RDDs):</strong> Immutable, fault-tolerant data collections distributed across the cluster.</li>
                <li><strong>DataFrames:</strong> Higher-level API for data manipulation, similar to Pandas DataFrames.</li>
                <li><strong>Spark SQL:</strong> Enables SQL-like operations on structured data.</li>
                <li><strong>Spark MLlib:</strong> Machine learning library for building and training models.</li>
                <li><strong>Spark Streaming:</strong> Framework for real-time data processing.</li>
            </ul>


            <h5>Advantages of PySpark</h5>
            <ul>
                <li><strong>Leverages Python's Ease of Use:</strong> Familiar syntax and extensive data science libraries in the Python ecosystem.</li>
                <li><strong>Scalability and Performance:</strong> Handles large datasets effectively on distributed clusters.</li>
                <li><strong>Versatility:</strong> Supports various data types, processing needs, and languages.</li>
            </ul>

            <h3>PySpark methods</h3>
            <table>
                <tr>
                    <th>Functionality</th>
                    <th>PySpark Method</th>
                </tr>
                <tr>
                    <td>SparkSession</td>
                    <td>
                        <ul>
                            <li><code>SparkSession.builder.appName()</code>: Set the application name.</li>
                            <li><code>SparkSession.builder.getOrCreate()</code>: Create a SparkSession or get an existing one.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Reading and Writing Data:</td>
                    <td>
                        <ul>
                            <li><code>spark.read.format().option().load()</code>: Read data from various sources.</li>
                            <li><code>DataFrame.write.format().mode().save()</code>: Write data to various storage systems.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>DataFrame Operations: </td>
                    <td>
                        <ul>
                            <li><code>DataFrame.show()</code>: Display the contents of a DataFrame.</li>
                            <li><code>DataFrame.select()</code>:  Select specific columns.</li>
                            <li><code>DataFrame.filter()</code>: Filter rows based on conditions.</li>
                            <li><code>DataFrame.groupBy()</code>:  Group data based on one or more columns.</li>
                            <li><code>DataFrame.join()</code>: Perform join operations between DataFrames.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Transformations:</td>
                    <td>
                        <ul>
                            <li><code>DataFrame.withColumn()</code>: Add or replace columns.</li>
                            <li><code>DataFrame.drop()</code>: Drop specified columns.</li>
                            <li><code>DataFrame.na.fill()</code>: DataFrame.na.fill()</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Actions</td>
                    <td>
                        <ul>
                            <li><code>DataFrame.count()</code>: Count the number of rows.</li>
                            <li><code>DataFrame.collect()</code>: Retrieve all data from the DataFrame.</li>
                            <li><code>DataFrame.take()</code>: Retrieve a specified number of rows.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>SQL Queries:</td>
                    <td>
                        <ul>
                            <li><code>DataFrame.createOrReplaceTempView()</code>: Register DataFrame as a temporary table.</li>
                            <li><code>spark.sql()</code>: Execute SQL queries on DataFrames.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Data Aggregation and Summary</td>
                    <td>
                        <ul>
                            <li><code>DataFrame.describe()</code>: Generates descriptive statistics</li>
                            <li><code>DataFrame.approxQuantile()</code>: Approximate quantiles of numerical columns.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Data Cleaning and Handling:</td>
                    <td>
                        <ul>
                            <li><code>DataFrame.dropDuplicates()</code>: Remove duplicate rows.</li>
                            <li><code>DataFrame.fillna()</code>:  Replace null values with specified values.</li>
                            <li><code>DataFrame.dropna()</code>: Remove rows with null values.</li>
                            <li><code>DataFrame.replace()</code>: Replace specified values.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Window Functions:</td>
                    <td>
                        <ul>
                            <li><code>pyspark.sql.functions.row_number()</code>: Assigns a unique number to each row within a partition.</li>
                            <li><code>pyspark.sql.functions.rank()</code>: Computes the rank of rows within a partition.</li>
                            <li><code>pyspark.sql.functions.lead()</code> and <code>pyspark.sql.functions.lag()</code>: Access data from subsequent or preceding rows.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Caching</td>
                    <td>
                        <ul>
                            <li><code>DataFrame.cache()</code>: Persist the DataFrame in memory for faster access.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Machine Learning:</td>
                    <td>
                        <ul>
                            <li>PySpark includes various MLlib functions for machine learning tasks.</li>
                            <li><code>pyspark.ml.Pipeline()</code>: Define a machine learning pipeline.</li>
                            <li>PySpark MLlib provides various algorithms for classification, regression, clustering, and collaborative filtering.</li>
                            <li>Methods like <code>pyspark.ml.classification.LogisticRegression()</code>, and <code>pyspark.ml.regression.LinearRegression()</code> etc.</li>
                        </ul>
                    </td>
                </tr>
                
                <tr>
                    <td>Statistical Functions:</td>
                    <td>
                        <ul>
                            <li><code>pyspark.sql.functions.corr()</code></li>
                            <li><code>pyspark.sql.functions.covar_pop()</code> and <code>pyspark.sql.functions.covar_samp()</code>: Compute population and sample covariance.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Time Series and Date Functions:</td>
                    <td>
                        <ul>
                            <li><code>pyspark.sql.functions.year()</code> and <code>pyspark.sql.functions.month()</code>: etc.: Extract components from a date.</li>
                            <li><code>pyspark.sql.functions.datediff()</code>: Calculate the difference between two dates</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Graph Processing (GraphFrames):</td>
                    <td>
                        <ul>
                            <li>GraphFrames is an extension of DataFrames for graph processing.</li>
                            <li>Methods like <code>g.vertices</code>, <code>g.edges</code>, <code>g.bfs()</code>, etc., for graph analysis.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>User-Defined Functions (UDFs):</td>
                    <td>
                        <ul>
                            <li><code>pyspark.sql.functions.udf()</code>: Define a User-Defined Function.
                            </li>
                            <li><code>pyspark.sql.functions.when()</code>: Conditional expressions in a DataFrame.</li>
                        </ul>
                    </td>
                </tr>
            </table>

            <br>
            <div class="box">
                <h3>Codes on GitHub</h3>
                For the details on how pyspark can be used to do data analytics of a large dataset is available at my 
                <a href="https://github.com/arunp77/Database-datapipeline-ETL/tree/main/pyspark" target="_blank">GitHub repository</a>.
                In this repository, I have done analysis on some examples datasets using Pyspark Dataframe and RDD methods. 
            </div>

            <br>
            <!-------------->
            <h3>RDD's Resilient Distributed Datasets (RDDs)</h3>
            The RDD structure is the elementary structure of Spark. It is flexible and optimal in performance for any  linear operation. 
            However, this structure has limited performance when it comes to non-linear operations.

            <h5>SparkContext:</h5>
            <code>SparkContext</code> is a crucial entry point for any Spark functionality in Apache Spark applications. It coordinates the execution of Spark jobs 
            and manages the resources allocated for these jobs. In Spark versions before 2.0, it was the main entry point for Spark, but in later versions, 
            <code>SparkSession</code> is typically used, which internally creates a <code>SparkContext</code> object.
            <ul>
                <li><strong>Definition: </strong><code>SparkContext</code> is the  main entry point for Spark functionality in Spark applications.</li>
                <li><strong>Purpose: </strong> It coordinates the execution of Spark jobs and manages the resources allocated for these jobs.</li>
                <li><strong>Usage: </strong> In older versions of Spark, it was directly created by developers. In newer versions, it's often implicitly created as part of a <code>SparkSession</code>.</li>
            </ul>

            To start a <code>SparkContext</code>, we typically create an instance of it in the Spark application code. However, in newer versions of Spark (2.0 and above), it's recommended to use 
            <code>SparkSession</code> instead, which internally manages the <code>SparkCOntext</code>. 

            <ul>
                <li><strong>Using SparkContext</strong>:
                    <pre class="language-python"><code>
                        from pyspark import SparkContext

                        # Create a SparkContext object
                        sc = SparkContext("local", "MyApp")
                    </code></pre>
                    In this example:
                    <ul>
                        <li>"local" specifies that Spark should run in local mode using a single thread.</li>
                        <li>"MyApp" is a name for your Spark application.</li>
                    </ul>
                </li>
                <li><strong>Using SparkSession</strong>: For newer versions of Spark, you typically use SparkSession, which internally creates a SparkContext. Here's how you do it:
                    <pre class="language-python"><code>
                        from pyspark.sql import SparkSession

                        # Create a SparkSession object
                        spark = SparkSession.builder \
                            .appName("MyApp") \
                            .getOrCreate() 
                    </code></pre>
                    In this case:
                    <ul>
                        <li>"MyApp" is also the name for your Spark application.</li>
                        <li>getOrCreate() method ensures that if a SparkSession already exists, it returns that session; otherwise, it creates a new one.</li>
                    </ul>
                </li>
            </ul>

            </section>

            <!-------Reference ------->
            <section id="reference">
                <h2>References</h2>
                <ol>
                    <li><a href="https://spark.apache.org/documentation.html" target="_blank"> Official Documentation</a></li>
                    <li><a href="https://www.databricks.com/learn/training/login" target="_blank">Databricks Learning Academy</a></li>
                    <li><a href="https://sparkbyexamples.com/" target="_blank">Spark by Examples</a></li>
                    <li><a href="https://www.datacamp.com/tutorial/pyspark-tutorial-getting-started-with-pyspark" target="_blank">Datacamp tutorial</a>.</li>
                    <li>For databricks, you can look at tutorial videos on youtube at <a href="https://www.youtube.com/watch?v=ChISx0-cMpU" target="_blank">youtube video by Bryan Cafferky</a>, 
                        writer of the book "Master Azure Databricks". A great playlist for someone who just want to learn about the big data analytics at Databricks Azure cloud platform.</li>
                    <li>See the video for <a href="https://www.youtube.com/watch?v=_C8kWso4ne4" target="_blank">pyspark basics by Krish Naik</a>. Great video for starter.</li>
                    <li><a href="https://www.youtube.com/watch?v=QLGrLFOzMRw" target="_blank">Great youtube on Apache spark</a> one premise working.</li>
                </ol> 
            </section>

            <hr>
        
            <div style="background-color: #f0f0f0; padding: 15px; border-radius: 5px;">

                <h3>Some other interesting things to know:</h3>
                <ul style="list-style-type: disc; margin-left: 30px;">
                    <li>Visit my website on <a href="sql-project.html">For Data, Big Data, Data-modeling, Datawarehouse, SQL, cloud-compute.</a></li>
                    <li>Visit my website on <a href="Data-engineering.html">Data engineering</a></li>
                </ul>
            </div>
            <p></p>

            <div class="navigation">
                
                <a href="index.html#portfolio" class="clickable-box">
                    <span class="arrow-left">Portfolio section</span>
                </a>
                
                <a href="Data-engineering.html" class="clickable-box">
                    <span class="arrow-right">Content</span>
                </a>

            </div>
        </div>
        </section><!-- End Portfolio Details Section -->
    </main><!-- End #main --

    <!-- ======= Footer ======= -->
    <footer id="footer">
    <div class="container">
        <div class="copyright">
        &copy; Copyright <strong><span>Arun</span></strong>
        </div>
    </div>
    </footer><!-- End  Footer -->

    <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

    <!-- Vendor JS Files -->
    <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
    <script src="assets/vendor/aos/aos.js"></script>
    <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
    <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
    <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
    <script src="assets/vendor/typed.js/typed.umd.js"></script>
    <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
    <script src="assets/vendor/php-email-form/validate.js"></script>

    <!-- Template Main JS File -->
    <script src="assets/js/main.js"></script>

    <script>
    document.addEventListener("DOMContentLoaded", function () {
        hljs.initHighlightingOnLoad();
    });
    </script>

</body>

</html>