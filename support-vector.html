<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1.0" name="viewport">

<title>SVM</title>
<meta content="" name="description">
<meta content="" name="keywords">

<!-- Favicons -->
<link href="assets/img/Favicon-1.png" rel="icon">
<link href="assets/img/Favicon-1.png" rel="apple-touch-icon">

<!-- Google Fonts -->
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

<!-- Vendor CSS Files -->
<link href="assets/vendor/aos/aos.css" rel="stylesheet">
<link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
<link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
<link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
<link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
<!-- Creating a python code section-->
<link rel="stylesheet" href="assets/css/prism.css">
<script src="assets/js/prism.js"></script>

<!-- Template Main CSS File -->
<link href="assets/css/style.css" rel="stylesheet">

<!-- To set the icon, visit https://fontawesome.com/account-->
<script src="https://kit.fontawesome.com/5d25c1efd3.js" crossorigin="anonymous"></script>
<!-- end of icon-->

<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
======================================================== -->
</head>

<body>

<!-- ======= Mobile nav toggle button ======= -->
<i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

<!-- ======= Header ======= -->
<header id="header">
<div class="d-flex flex-column">

    <div class="profile">
    <img src="assets/img/myphoto.jpeg" alt="" class="img-fluid rounded-circle">
    <h1 class="text-light"><a href="index.html">Arun</a></h1>
    <div class="social-links mt-3 text-center">
        <a href="https://www.linkedin.com/in/arunp77/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        <a href="https://github.com/arunp77" class="github"><i class="bx bxl-github"></i></a>
        <a href="https://twitter.com/arunp77_" class="twitter"><i class="bx bxl-twitter"></i></a>
        <a href="https://www.instagram.com/arunp77/" class="instagram"><i class="bx bxl-instagram"></i></a>
        <a href="https://arunp77.medium.com/" class="medium"><i class="bx bxl-medium"></i></a>
    </div>
    </div>

    <nav id="navbar" class="nav-menu navbar">
    <ul>
        <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
        <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
        <li><a href="index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
        <li><a href="index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
        <li><a href="index.html#skills-and-tools" class="nav-link scrollto"><i class="bx bx-wrench"></i> <span>Skills and Tools</span></a></li>
        <li><a href="index.html#services" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Services</span></a></li>
        <li><a href="index.html#professionalcourses" class="nav-link scrollto"><i class="bx bx-book-alt"></i> <span>Professional Certification</span></a></li>
        <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-news"></i> <span>Publications</span></a></li>
        <li><a href="index.html#extra-curricular" class="nav-link scrollto"><i class="bx bx-rocket"></i> <span>Extra-Curricular Activities</span></a></li>
        <li><a href="index.html#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
    </ul>
    </nav><!-- .nav-menu -->
</div>
</header><!-- End Header -->

<main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section id="breadcrumbs" class="breadcrumbs">
    <div class="container">

    <div class="d-flex justify-content-between align-items-center">
        <h2>Machine Learning</h2>
        <ol>
        <li><a href="machine-learning.html" class="clickable-box">Content section</a></li>
        <li><a href="index.html#portfolio" class="clickable-box">Portfolio section</a></li>
        </ol>
    </div>

    </div>
    </section><!-- End Breadcrumbs -->

    <!------  right dropdown menue ------->
    <div class="right-side-list">
    <div class="dropdown">
        <button class="dropbtn"><strong>Shortcuts:</strong></button>
        <div class="dropdown-content">
            <ul>
                <li><a href="cloud-compute.html"><i class="fas fa-cloud"></i> Cloud</a></li>
                <li><a href="AWS-GCP.html"><i class="fas fa-cloud"></i> AWS-GCP</a></li>
                <li><a href="amazon-s3.html"><i class="fas fa-cloud"></i> AWS S3</a></li>
                <li><a href="ec2-confi.html"><i class="fas fa-server"></i> EC2</a></li>
                <li><a href="Docker-Container.html"><i class="fab fa-docker" style="color: rgb(29, 27, 27);"></i> Docker</a></li>
                <li><a href="Jupyter-nifi.html"><i class="fab fa-python" style="color: rgb(34, 32, 32);"></i> Jupyter-nifi</a></li>
                <li><a href="snowflake-task-stream.html"><i class="fas fa-snowflake"></i> Snowflake</a></li>
                <li><a href="data-model.html"><i class="fas fa-database"></i> Data modeling</a></li>
                <li><a href="sql-basics.html"><i class="fas fa-table"></i> QL</a></li>
                <li><a href="sql-basic-details.html"><i class="fas fa-database"></i> SQL</a></li>
                <li><a href="Bigquerry-sql.html"><i class="fas fa-database"></i> Bigquerry</a></li>
                <li><a href="scd.html"><i class="fas fa-archive"></i> SCD</a></li>
                <li><a href="sql-project.html"><i class="fas fa-database"></i> SQL project</a></li>
                <!-- Add more subsections as needed -->
            </ul>
        </div>
    </div>
    </div>

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
    <div class="container">
    <div class="row gy-4">
        <h1>Support Vector Algorithm: Classification methods</h1>
        <div class="col-lg-8">
        <div class="portfolio-details-slider swiper">
            <div class="swiper-wrapper align-items-center">

                <figure>
                    <img src="assets/img/machine-ln/classification-svm.png" alt="" style="max-width: 90%; max-height: auto;">
                    <figcaption style="text-align: center;"></figcaption>
                </figure>

            </div>
        </div>
    </div>

    <div class="col-lg-4 grey-box">
        
        <div class="section-title">
        <h3>Content</h3>
        <ol>
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#principle">Principle of KNN</a></li>
            <ul>
                <li><a href="#distance">Distance metrics for k-nearest neighbours</a></li>
                <li><a href="#when">When Do We Use the KNN Algorithm?</a></li>
                <li><a href="#steps-to-follow">Steps to Effective K-Nearest Neighbors (KNN) Algorithm Implementation</a></li>
                <li><a href="#what-k">What value should you choose for k in k-nearest neighbours</a></li>
                <li><a href="why-knn">Why Do We Need the KNN Algorithm?</a></li>
                <li><a href="#pros">Pros of using KNN</a></li>
                <li><a href="#cons">Cons of Using KNN</a></li>
            </ul>
            <li><a href="#example">Example</a></li>
            <li><a href="#reference">Reference</a></li>  
        </ol>
        </div>
    </div>
    </div>

    <section>
    <!-------------------- Introduction ---------------------->
    <h2 id="introdction">Introduction</h2>
    <ul>
        <li>Support Vector Machine (SVM) is undoubtedly one of the most popular ML algorithms used by machine learning practitioners. It is a supervised machine learning algorithm that is robust to outliers and generalizes well in many cases. However, the intuitive idea behind SVM can be a bit tricky to understand for a beginner. The name in itself is quite intimidating, Support, Vector, and Machine.</li>
        <li>It is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning.</li>
        <li>In this algorithm, we try to find a hyperplane that best separates the two classes. It is to be noted that, it may seems that the SVM and logisitc regression are similar. Both the algorithms try to find the best hyperplane, but the main difference is logistic regression is a probabilistic approach whereas support vector machine is based on statistical approaches.</li>
        <li>Now the question is which hyperplane does it select? There can be an infinite number of hyperplanes passing through a point and classifying the two classes perfectly. So, which one is the best? Well, SVM does this by finding the maximum margin between the hyperplanes that means maximum distances between the two classes.</li>
    </ul>
    <div class="grey-box">
        <p><strong>Logistic Regression vs Support Vector Machine (SVM): </strong>
        Depending on the number of features you have you can either choose Logistic Regression or SVM. SVM works best when the dataset is small and complex. It is usually advisable to first use logistic regression and see how does it performs, if it fails to give a good accuracy you can go for SVM without any kernel. Logistic regression and SVM without any kernel have similar performance but depending on your features, one may be more efficient than the other.</p>
        <table>
            <tr>
                <th>Feature</th>
                <th>Logisitc Regression</th>
                <th>Support Vecotr Machine (SVM)</th>
            </tr>
            <tr>
                <td>Type</td>
                <td>Discriminative model</td>
                <td>Discriminative model</td>
            </tr>
            <tr>
                <td>Decision Boundary</td>
                <td>Linear or Non-linear</td>
                <td>Linear or Non-linear</td>
            </tr>
            <tr>
                <td>Interpretability</td>
                <td>Easy to interpret coefficients</td>
                <td>Less interpretable due to complex decision boundaries</td>
            </tr>
            <tr>
                <td>Training Speed</td>
                <td>Faster</td>
                <td>Slower, especially with large datasets</td>
            </tr>
            <tr>
                <td>Regularization</td>
                <td>L1 or L2 regularization</td>
                <td>Regularization via margin parameter (C)</td>
            </tr>
            <tr>
                <td>Handling Noise</td>
                <td>Sensitive to noisy data</td>
                <td>More robust to noisy data</td>
            </tr>
            <tr>
                <td>Scalability</td>
                <td>Suitable for large datasets</td>
                <td>Can be computationally expensive with large datasets</td>
            </tr>
            <tr>
                <td>Performance on Small Data</td>
                <td>May underperform if features are not linearly separable</td>
                <td>Can handle non-linear data well, even with small datasets</td>
            </tr>
            <tr>
                <td>Parameters to Tune</td>
                <td>Regularization strength, threshold</td>
                <td>Regularization parameter (C), kernel function, gamma</td>
            </tr>
            <tr>
                <td>Application Areas</td>
                <td>Commonly used in binary classification tasks and probability estimation</td>
                <td>Widely used in classification tasks with non-linear decision boundaries</td>
            </tr>
            <tr>
                <td>Implementation</td>
                <td>Available in most machine learning libraries</td>
                <td>Available in most machine learning libraries</td>
            </tr>
            
        </table>
    </div>

    <!--------------------------------->
    <h3 id="types-svm">Types of Support Vector Machine (SVM) Algorithms</h3>
    <p>Support Vector Machines (SVMs) offer various algorithms for classification and regression tasks, primarily distinguished by the types of decision boundaries they create and the techniques they employ for optimization. Here are some common types of SVM algorithms:</p>
    <ol>
        <li><strong>Linear SVM:</strong> This algorithm is used when the data is linearly separable. Perfectly linearly separable means that the data points can be classified into 2 classes by using a single straight line(if 2D). It aims to find the optimal hyperplane that separates the classes with the maximum margin.</li>

        <li><strong>Non-linear SVM:</strong> When the data is not linearly separable then we can use Non-Linear SVM, which means when the data points cannot be separated into 2 classes by using a straight line (if 2D) then we use some advanced techniques like kernel tricks to classify them. In most real-world applications we do not find linearly separable datapoints hence we use kernel trick to solve them.</li>
        
        <li><strong>Support Vector Regression (SVR):</strong> Unlike classification tasks, SVR is used for regression tasks. It aims to find the optimal hyperplane that best fits the data while minimizing the margin violations.</li>
        
        <li><strong>Nu-SVM:</strong> This algorithm is an extension of the traditional SVM, introducing a parameter "nu" that replaces the regularization parameter "C." It offers a more intuitive control over the number of support vectors and margin errors.</li>
        
        <li><strong>One-Class SVM:</strong> Primarily used for anomaly detection, this algorithm learns a decision boundary that encompasses the majority of the data points while treating the rest as outliers.</li>
        
        <li><strong>Sequential Minimal Optimization (SMO):</strong> SMO is an algorithm for training SVMs, particularly useful for solving large-scale optimization problems by decomposing them into smaller sub-problems.</li>
        
        <li><strong>Least Squares SVM (LS-SVM):</strong> This variant of SVM reformulates the optimization problem as a set of linear equations, making it computationally efficient for large-scale datasets.</li>
        
        <li><strong>Budgeted SVM:</strong> Designed for scenarios with limited computational resources, this algorithm dynamically selects a subset of support vectors to reduce computational complexity while maintaining classification accuracy.</li>
    </ol>

    <!---------------------------------------->
    <h3 id="terminology">Important terminologies</h3>
    <p>Here are some important terms in the context of Support Vector Machines (SVM):</p>
    <ul>
        <li><strong>Hyperplane:</strong> In SVM, a hyperplane is a decision boundary that separates classes in a feature space. For a binary classification problem, it's a line in 2D space, a plane in 3D space, and a higher-dimensional surface in higher dimensions.</li>
        <li><strong>Margin:</strong> The margin is the distance between the hyperplane and the nearest data points of each class. SVM aims to maximize this margin, as it represents the separation between classes. Maximizing the margin helps improve generalization and reduces the risk of overfitting.</li>
        <li><strong>Support Vectors:</strong> These are the data points that lie closest to the decision boundary (hyperplane). They determine the position and orientation of the hyperplane and are crucial in defining the margin. Only these points influence the construction of the hyperplane; hence, they are called support vectors.</li>
        <li><strong>Kernel Trick:</strong> SVMs can efficiently handle non-linear decision boundaries by using kernel functions. The kernel trick involves implicitly mapping the input features into a higher-dimensional space, where the classes are more likely to be separable. Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.</li>
        <li><strong>Regularization Parameter (C):</strong> The regularization parameter (C) controls the trade-off between maximizing the margin and minimizing the classification error. A smaller C value leads to a larger margin but may result in misclassification of some training examples (soft margin). Conversely, a larger C value allows more training examples to be correctly classified but may lead to a smaller margin (hard margin). Proper tuning of C is crucial to prevent overfitting.</li>
        <li><strong>Kernel Parameters:</strong> For kernelized SVMs, there are additional parameters to tune, such as gamma (\(\gamma\)) for RBF kernel and degree for polynomial kernel. These parameters control the flexibility of the decision boundary. Proper selection of kernel parameters is essential for achieving good performance and avoiding overfitting.</li>
        <li><strong>Dual Problem:</strong> The optimization problem in SVM can be reformulated into its dual form, which involves maximizing a function subject to constraints. Solving the dual problem is often more computationally efficient, especially when using kernel functions.</li>
        <li><strong>Nu Parameter:</strong> In Nu-SVM, the nu parameter replaces the C parameter and controls the upper bound on the fraction of margin errors and support vectors. It offers a more intuitive way to adjust the model complexity.</li>
    </ul>

    <!---------------------------------->
    <h4 id="intuition">Intuition</h4>
    <p>Imagine countries A & B sharing their border and having a truce. This border separates citizens of country A from that of country B. The border is kept vigilante by the armed forces of the two countries. They make sure that there is no violations/movement of citizens across the border. The countries also share a disputed piece of land that is under nobody’s territory and hence generally called a No Man’s Land. Pictorially, this scenario looks like image-(a):</p>

    <figure>
        <img src="assets/img/machine-ln/classification-svm-example.png" alt="" style="max-width: 90%; max-height: auto;">
        <figcaption style="text-align: center;">(<strong>Image credit:</strong> <a href="https://www.newtechdojo.com/understanding-support-vector-machines-svm/" target="_blank">newtechdojo</a>)</figcaption>
    </figure>
    <p>In this diagram, notice how only the soldiers are needed to keep the border (solid line). In other words, only these soldiers are required to support the border shape. Notice that all the citizens of a given country can roam freely within the country’s territories. But even if a single soldier backs away, there are chances that the enemy can gain some ground and the border is moved. This situation is discussed in the below figure-(b). It should be noted here that the border separates citizens of one country from that of another. Only the soldiers are required to keep the border. There is an empty land around the border that no one claims. Soldiers are closest to the border and other citizens are far away.</p>
    <p>A few things to note here:</p>
    <ul>
        <li>The border separates citizens of one country from that of another.</li>
        <li>Only the soldiers are required to keep the border.</li>
        <li>There is an empty land around the border that no one claims.</li>
        <li>Soldiers are closest to the border and other citizens are far away.</li>
    </ul>



    classification-svm-example
    





    </section>

    <!----------- Reference ----------->
    <section id="reference">
    <h2>References</h2>
    <ul>
        <li><a href="https://arunp77.github.io/logistic-regression.html#con-mat" target="_blank">Confusion matrix details</a>.</li>
        <li>My github Repositories on Remote sensing <a href="https://github.com/arunp77/Machine-Learning/" target="_blank">Machine learning</a></li>
        <li><a href="https://mlu-explain.github.io/linear-regression/" target="_blank">A Visual Introduction To Linear regression</a> (Best reference for theory and visualization).</li>
        <li>Book on Regression model: <a href="https://avehtari.github.io/ROS-Examples/" target="_blank">Regression and Other Stories</a></li>
        <li>Book on Statistics: <a href="https://hastie.su.domains/Papers/ESLII.pdf" target="_blank">The Elements of Statistical Learning</a></li>
        <li><a href="https://www.javatpoint.com/machine-learning-naive-bayes-classifier" target="_blank">Naïve Bayes Classifier Algorithm, JAVAPoint.com</a></li>
        <li><a href="https://www.colorado.edu/amath/sites/default/files/attached-files/ch12_0.pdf">https://www.colorado.edu/amath/sites/default/files/attached-files/ch12_0.pdf</a></li>
        <li><a href="https://datahacker.rs/002-machine-learning-linear-regression-model/" target="_blank">One of the best description on Linear regression</a>.</li>
    </ul>
    </section>

    <hr>
    
    <div style="background-color: #f0f0f0; padding: 15px; border-radius: 5px;">

    <h3>Some other interesting things to know:</h3>
    <ul style="list-style-type: disc; margin-left: 30px;">
        <li>Visit my website on <a href="sql-project.html">For Data, Big Data, Data-modeling, Datawarehouse, SQL, cloud-compute.</a></li>
        <li>Visit my website on <a href="Data-engineering.html">Data engineering</a></li>
    </ul>
    </div>
    <p></p>

    <div class="navigation">
        <a href="index.html#portfolio" class="clickable-box">
            <span class="arrow-left">Portfolio section</span>
        </a>
        
        <a href="machine-learning.html" class="clickable-box">
            <span class="arrow-right">Content</span>
        </a>
    </div>
</div>
</div>
</section><!-- End Portfolio Details Section -->
</main><!-- End #main --

<!-- ======= Footer ======= -->
<footer id="footer">
  <div class="container">
    <div class="copyright">
      &copy; Copyright <strong><span>Arun</span></strong>
    </div>
  </div>
</footer><!-- End  Footer -->

<a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

<!-- Vendor JS Files -->
<script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
<script src="assets/vendor/typed.js/typed.umd.js"></script>
<script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    hljs.initHighlightingOnLoad();
  });
</script>

</body>

</html>